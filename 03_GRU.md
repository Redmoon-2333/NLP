## 3.3 GRUï¼ˆé—¨æ§å¾ªç¯å•å…ƒï¼‰

### 3.3.1 æ¦‚è¿°

**è®¾è®¡åŠ¨æœºï¼š**

LSTMè™½ç„¶æœ‰æ•ˆè§£å†³äº†é•¿æœŸä¾èµ–é—®é¢˜ï¼Œä½†å…¶ç»“æ„ç›¸å¯¹å¤æ‚ï¼ŒåŒ…å«ä¸‰ä¸ªé—¨æ§å’Œä¸¤æ¡çŠ¶æ€ä¼ é€’è·¯å¾„ï¼ˆéšè—çŠ¶æ€hâ‚œå’Œç»†èƒçŠ¶æ€Câ‚œï¼‰ã€‚è¿™å¯¼è‡´ï¼š
- å‚æ•°é‡è¾ƒå¤§ï¼ˆçº¦4å€äºæ ‡å‡†RNNï¼‰
- è®¡ç®—æˆæœ¬è¾ƒé«˜
- è®­ç»ƒæ—¶é—´è¾ƒé•¿

2014å¹´ï¼ŒChoç­‰äººåœ¨è®ºæ–‡ã€ŠLearning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translationã€‹ä¸­æå‡ºäº†GRUï¼ˆGated Recurrent Unitï¼‰ï¼Œæ—¨åœ¨ä¿æŒLSTMè§£å†³é•¿æœŸä¾èµ–èƒ½åŠ›çš„åŒæ—¶ï¼Œç®€åŒ–æ¨¡å‹ç»“æ„ã€‚

**æ ¸å¿ƒæ€æƒ³ï¼š**

**LSTM vs GRU è®¾è®¡å¯¹æ¯”ï¼š**

| ç‰¹æ€§ | LSTM | GRU |
|------|------|-----|
| **çŠ¶æ€æ•°é‡** | 2ä¸ªï¼ˆç»†èƒçŠ¶æ€ Câ‚œ + éšè—çŠ¶æ€ hâ‚œï¼‰ | 1ä¸ªï¼ˆéšè—çŠ¶æ€ hâ‚œï¼‰ |
| **é—¨æ§æ•°é‡** | 3ä¸ªï¼ˆé—å¿˜é—¨ã€è¾“å…¥é—¨ã€è¾“å‡ºé—¨ï¼‰ | 2ä¸ªï¼ˆæ›´æ–°é—¨ã€é‡ç½®é—¨ï¼‰ |
| **å‚æ•°é‡** | 4 Ã— (input_size + hidden_size) Ã— hidden_size | 3 Ã— (input_size + hidden_size) Ã— hidden_size |
| **æ•ˆæœ** | - | å‚æ•°é‡å‡å°‘çº¦25%ï¼Œè®­ç»ƒé€Ÿåº¦æå‡ï¼Œæ€§èƒ½ç›¸å½“ |

### 3.3.2 åŸºç¡€ç»“æ„

GRUå°†LSTMçš„ç»†èƒçŠ¶æ€å’Œéšè—çŠ¶æ€åˆå¹¶ä¸ºä¸€ä¸ªå•ä¸€çš„éšè—çŠ¶æ€ï¼Œå¹¶é€šè¿‡ä¸¤ä¸ªé—¨æ§æ¥æ§åˆ¶ä¿¡æ¯çš„æµåŠ¨ã€‚

**æ•´ä½“ç»“æ„å›¾ï¼š**

```mermaid
flowchart TB
    subgraph GRUCell["GRU Cell ç»“æ„"]
        direction TB

        %% è¾“å…¥
        Ht_prev(["hâ‚œâ‚‹â‚<br/>ä¸Šä¸€æ—¶åˆ»éšè—çŠ¶æ€"])
        Xt(["xâ‚œ<br/>å½“å‰è¾“å…¥"])

        %% é—¨æ§
        ResetGate["é‡ç½®é—¨ râ‚œ"]
        UpdateGate["æ›´æ–°é—¨ zâ‚œ"]

        %% å€™é€‰çŠ¶æ€
        Candidate["å€™é€‰çŠ¶æ€ hÌƒâ‚œ"]

        %% éšè—çŠ¶æ€æ›´æ–°
        Update["hâ‚œ = (1-zâ‚œ)âŠ™hâ‚œâ‚‹â‚ + zâ‚œâŠ™hÌƒâ‚œ"]

        %% è¾“å‡º
        Ht(["hâ‚œ<br/>å½“å‰éšè—çŠ¶æ€"])
        Yt(["yâ‚œ<br/>å½“å‰è¾“å‡º"])

        %% è¿æ¥
        Ht_prev --> ResetGate
        Ht_prev --> UpdateGate
        Xt --> ResetGate
        Xt --> UpdateGate
        ResetGate --> Candidate
        UpdateGate --> Update
        Candidate --> Update
        Update --> Ht --> Yt
    end

    style GRUCell fill:#f0f8ff,stroke:#333,stroke-width:2px
    style ResetGate fill:#9b59b6,stroke:#333,stroke-width:2px,color:#fff
    style UpdateGate fill:#e67e22,stroke:#333,stroke-width:2px,color:#fff
    style Candidate fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style Update fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style Ht_prev fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style Xt fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style Ht fill:#2ecc71,stroke:#333,stroke-width:2px
    style Yt fill:#2ecc71,stroke:#333,stroke-width:2px
```

**ä¸¤ä¸ªé—¨æ§æœºåˆ¶è¯¦è§£ï¼š**

**1. é‡ç½®é—¨ï¼ˆReset Gateï¼‰â€”â€” å†³å®šé—å¿˜å¤šå°‘å†å²ä¿¡æ¯**

**é‡ç½®é—¨ï¼ˆReset Gateï¼‰ï¼š**

- **åŠŸèƒ½**ï¼šæ§åˆ¶å‰ä¸€æ—¶åˆ»éšè—çŠ¶æ€æœ‰å¤šå°‘ä¿¡æ¯è¢«ç”¨äºè®¡ç®—å€™é€‰çŠ¶æ€
- **è®¡ç®—**ï¼š`râ‚œ = Ïƒ(Wr Â· [hâ‚œâ‚‹â‚, xâ‚œ])`
- **è¾“å‡º**ï¼š`râ‚œ âˆˆ (0, 1)`
  - `0` = å®Œå…¨é—å¿˜å†å²
  - `1` = å®Œå…¨ä¿ç•™å†å²
- **ä½œç”¨**ï¼šç±»ä¼¼äºLSTMçš„é—å¿˜é—¨ï¼Œä½†ç›´æ¥ä½œç”¨äºéšè—çŠ¶æ€
- **ç›´è§‚ç†è§£**ï¼š
  - `râ‚œ â‰ˆ 0`ï¼š"å¿˜è®°ä¹‹å‰çš„è®°å¿†ï¼Œä¸»è¦å…³æ³¨å½“å‰è¾“å…¥"
  - `râ‚œ â‰ˆ 1`ï¼š"ä¿ç•™ä¹‹å‰çš„è®°å¿†ï¼Œç»“åˆå½“å‰è¾“å…¥"

**2. æ›´æ–°é—¨ï¼ˆUpdate Gateï¼‰â€”â€” å†³å®šéšè—çŠ¶æ€çš„æ›´æ–°ç¨‹åº¦**

**æ›´æ–°é—¨ï¼ˆUpdate Gateï¼‰ï¼š**

- **åŠŸèƒ½**ï¼šæ§åˆ¶å‰ä¸€æ—¶åˆ»éšè—çŠ¶æ€å’Œæ–°å€™é€‰çŠ¶æ€çš„æ··åˆæ¯”ä¾‹
- **è®¡ç®—**ï¼š`zâ‚œ = Ïƒ(Wz Â· [hâ‚œâ‚‹â‚, xâ‚œ])`
- **è¾“å‡º**ï¼š`zâ‚œ âˆˆ (0, 1)`
  - `0` = ä¿ç•™æ—§çŠ¶æ€
  - `1` = æ¥å—æ–°çŠ¶æ€
- **ä½œç”¨**ï¼šåˆå¹¶äº†LSTMçš„é—å¿˜é—¨å’Œè¾“å…¥é—¨çš„åŠŸèƒ½
- **ç›´è§‚ç†è§£**ï¼š
  - `zâ‚œ â‰ˆ 0`ï¼š"ä¿æŒä¹‹å‰çš„è®°å¿†ä¸å˜"
  - `zâ‚œ â‰ˆ 1`ï¼š"ç”¨æ–°è®¡ç®—çš„çŠ¶æ€æ›¿æ¢æ—§çŠ¶æ€"
  - `zâ‚œ âˆˆ (0,1)`ï¼š"æ–°æ—§çŠ¶æ€æŒ‰æ¯”ä¾‹æ··åˆ"

**éšè—çŠ¶æ€æ›´æ–°ï¼ˆGRUçš„æ ¸å¿ƒï¼‰ï¼š**

**ç¬¬ä¸€æ­¥ï¼šè®¡ç®—å€™é€‰éšè—çŠ¶æ€**

```
hÌƒâ‚œ = tanh(W Â· [râ‚œ âŠ™ hâ‚œâ‚‹â‚, xâ‚œ])
```

- `râ‚œ âŠ™ hâ‚œâ‚‹â‚`ï¼šé‡ç½®é—¨è¿‡æ»¤åçš„å†å²ä¿¡æ¯
- `[Â·, Â·]`ï¼šæ‹¼æ¥æ“ä½œ
- `tanh`ï¼šéçº¿æ€§æ¿€æ´»

**ç¬¬äºŒæ­¥ï¼šæ›´æ–°éšè—çŠ¶æ€**

```
hâ‚œ = (1 - zâ‚œ) âŠ™ hâ‚œâ‚‹â‚ + zâ‚œ âŠ™ hÌƒâ‚œ
        â†‘              â†‘
   ä¿ç•™æ—§è®°å¿†      æ·»åŠ æ–°è®°å¿†
```

**å¯¹æ¯”LSTMï¼š**

| æ¨¡å‹ | çŠ¶æ€æ›´æ–°å…¬å¼ | é—¨æ§æ–¹å¼ |
|------|-------------|----------|
| LSTM | Câ‚œ = fâ‚œâŠ™Câ‚œâ‚‹â‚ + iâ‚œâŠ™CÌƒâ‚œ | ä¸¤ä¸ªç‹¬ç«‹é—¨ï¼ˆé—å¿˜é—¨+è¾“å…¥é—¨ï¼‰ |
| GRU | hâ‚œ = (1-zâ‚œ)âŠ™hâ‚œâ‚‹â‚ + zâ‚œâŠ™hÌƒâ‚œ | ä¸€ä¸ªé—¨æ§åˆ¶ä¸¤è€…ï¼ˆæ›´æ–°é—¨ï¼‰ |

**ä¼˜åŠ¿ï¼š** zâ‚œåŒæ—¶æ§åˆ¶é—å¿˜å’Œè¾“å…¥ï¼Œå‚æ•°æ›´å°‘ï¼Œè®¡ç®—æ›´å¿«

**GRUä¸LSTMçš„å¯¹æ¯”å›¾ç¤ºï¼š**

| ç‰¹æ€§ | LSTMï¼ˆå¤æ‚ï¼‰ | GRUï¼ˆç®€åŒ–ï¼‰ |
|------|-------------|-------------|
| **çŠ¶æ€** | Câ‚œï¼ˆç»†èƒçŠ¶æ€ï¼‰+ hâ‚œï¼ˆéšè—çŠ¶æ€ï¼‰ | hâ‚œï¼ˆä»…éšè—çŠ¶æ€ï¼‰ |
| **é—¨æ§** | é—å¿˜é—¨ã€è¾“å…¥é—¨ã€è¾“å‡ºé—¨ï¼ˆ3ä¸ªï¼‰ | é‡ç½®é—¨ã€æ›´æ–°é—¨ï¼ˆ2ä¸ªï¼‰ |
| **è®¡ç®—æµç¨‹** | Câ‚œâ‚‹â‚ â†’ [é—å¿˜é—¨] â†’ Câ‚œ â†’ [è¾“å‡ºé—¨] â†’ hâ‚œ<br>hâ‚œâ‚‹â‚ â†’ [è¾“å…¥é—¨] â†’ Câ‚œ | hâ‚œâ‚‹â‚ â†’ [é‡ç½®é—¨] â†’ hâ‚œ<br>hâ‚œâ‚‹â‚ â†’ [æ›´æ–°é—¨] â†’ hâ‚œ |

### 3.3.3 å¤šå±‚ç»“æ„

**åŠ¨æœºï¼š** å•å±‚GRUåªèƒ½æ•æ‰åŸºç¡€çš„åºåˆ—ç‰¹å¾ï¼Œå¤šå±‚GRUå¯ä»¥å­¦ä¹ å±‚æ¬¡åŒ–çš„è¡¨ç¤ºï¼Œæ•æ‰æ›´å¤æ‚çš„æ¨¡å¼ã€‚

**ç»“æ„è®¾è®¡ï¼š**

```mermaid
flowchart TB
    subgraph Input["è¾“å…¥å±‚ï¼ˆè¯åµŒå…¥ï¼‰"]
        direction LR
        X1(["xâ‚"])
        X2(["xâ‚‚"])
        X3(["xâ‚ƒ"])
        X4(["xâ‚„"])
        X1 --> X2 --> X3 --> X4
    end

    subgraph Layer1["ç¬¬1å±‚ GRU - è¯çº§ç‰¹å¾"]
        direction LR
        H11(["hâ‚â½Â¹â¾"])
        H12(["hâ‚‚â½Â¹â¾"])
        H13(["hâ‚ƒâ½Â¹â¾"])
        H14(["hâ‚„â½Â¹â¾"])
        H11 --> H12 --> H13 --> H14
    end

    subgraph Layer2["ç¬¬2å±‚ GRU - çŸ­è¯­ç‰¹å¾"]
        direction LR
        H21(["hâ‚â½Â²â¾"])
        H22(["hâ‚‚â½Â²â¾"])
        H23(["hâ‚ƒâ½Â²â¾"])
        H24(["hâ‚„â½Â²â¾"])
        H21 --> H22 --> H23 --> H24
    end

    subgraph Layer3["ç¬¬3å±‚ GRU - é«˜å±‚è¯­ä¹‰"]
        direction LR
        H31(["hâ‚â½Â³â¾"])
        H32(["hâ‚‚â½Â³â¾"])
        H33(["hâ‚ƒâ½Â³â¾"])
        H34(["hâ‚„â½Â³â¾"])
        H31 --> H32 --> H33 --> H34
    end

    Input --> Layer1
    Layer1 --> Layer2
    Layer2 --> Layer3

    style X1 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style X2 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style X3 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style X4 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style H11 fill:#2ecc71,stroke:#333,stroke-width:2px
    style H12 fill:#2ecc71,stroke:#333,stroke-width:2px
    style H13 fill:#2ecc71,stroke:#333,stroke-width:2px
    style H14 fill:#2ecc71,stroke:#333,stroke-width:2px
    style H21 fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style H22 fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style H23 fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style H24 fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style H31 fill:#1e8449,stroke:#333,stroke-width:2px,color:#fff
    style H32 fill:#1e8449,stroke:#333,stroke-width:2px,color:#fff
    style H33 fill:#1e8449,stroke:#333,stroke-width:2px,color:#fff
    style H34 fill:#1e8449,stroke:#333,stroke-width:2px,color:#fff
```

**å±‚æ¬¡ç‰¹å¾å­¦ä¹ ï¼š**

| å±‚çº§ | å­¦ä¹ ç‰¹å¾ | é¢œè‰² | ç¤ºä¾‹ç†è§£ |
|------|----------|------|----------|
| ç¬¬1å±‚ | è¯çº§ç‰¹å¾ | ğŸŸ¢ æµ…ç»¿ | "æˆ‘"ã€"å–œæ¬¢"ã€"NLP" ç­‰å•ä¸ªè¯çš„å«ä¹‰ |
| ç¬¬2å±‚ | çŸ­è¯­ç‰¹å¾ | ğŸŸ¢ ä¸­ç»¿ | "å–œæ¬¢NLP" = åŠ¨è¯ + åè¯çš„ç»„åˆ |
| ç¬¬3å±‚ | é«˜å±‚è¯­ä¹‰ | ğŸŸ¢ æ·±ç»¿ | "æˆ‘å–œæ¬¢NLP" = å®Œæ•´å¥å­çš„è¯­ä¹‰ |

**å…³é”®ç‰¹æ€§ï¼š** ä½å±‚è¾“å‡ºä½œä¸ºé«˜å±‚è¾“å…¥ï¼Œé€å±‚æŠ½è±¡ï¼Œå½¢æˆå±‚æ¬¡åŒ–è¡¨ç¤º

---

**å‰å‘ä¼ æ’­è¿‡ç¨‹ï¼š**

```python
def forward(self, x):
    # x: (batch_size, seq_len, input_size)
    
    # ç¬¬1å±‚å‰å‘ä¼ æ’­
    out1, h1 = self.gru1(x)
    
    # ç¬¬2å±‚å‰å‘ä¼ æ’­ï¼ˆè¾“å…¥ä¸ºç¬¬1å±‚çš„è¾“å‡ºï¼‰
    out2, h2 = self.gru2(out1)
    
    # ç¬¬3å±‚å‰å‘ä¼ æ’­ï¼ˆè¾“å…¥ä¸ºç¬¬2å±‚çš„è¾“å‡ºï¼‰
    out3, h3 = self.gru3(out2)
    
    return out3, h3
```

**å¤šå±‚GRUçš„ä¼˜åŠ¿ï¼š**

| å±‚æ•° | ä¼˜åŠ¿ | é€‚ç”¨åœºæ™¯ |
|------|------|----------|
| 1å±‚ | è®¡ç®—å¿«ï¼Œé€‚åˆç®€å•ä»»åŠ¡ | çŸ­åºåˆ—åˆ†ç±»ã€åŸºæœ¬é¢„æµ‹ |
| 2-3å±‚ | å¹³è¡¡æ€§èƒ½å’Œå¤æ‚åº¦ | å¤§å¤šæ•°NLPä»»åŠ¡ |
| 3å±‚ä»¥ä¸Š | æ•è·å¤æ‚æ¨¡å¼ | æœºå™¨ç¿»è¯‘ã€å¯¹è¯ç³»ç»Ÿ |

**æ³¨æ„äº‹é¡¹ï¼š**
- å±‚æ•°è¶Šå¤šï¼Œå‚æ•°é‡è¶Šå¤§ï¼Œè¶Šå®¹æ˜“è¿‡æ‹Ÿåˆ
- éœ€è¦æ›´å¤šæ•°æ®å’Œæ›´å¼ºçš„æ­£åˆ™åŒ–ï¼ˆå¦‚dropoutï¼‰
- è®­ç»ƒæ—¶é—´ä¼šæ˜¾è‘—å¢åŠ 

### 3.3.4 åŒå‘ç»“æ„

**åŠ¨æœºï¼š** ä¼ ç»ŸGRUåªè€ƒè™‘è¿‡å»çš„ä¿¡æ¯ï¼ˆä»å·¦åˆ°å³å¤„ç†ï¼‰ï¼Œè€ŒåŒå‘GRUåŒæ—¶è€ƒè™‘è¿‡å»å’Œæœªæ¥çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

**ç»“æ„è®¾è®¡ï¼š**

```mermaid
flowchart TB
    subgraph Input["è¾“å…¥åºåˆ—"]
        direction LR
        X1(["æˆ‘"])
        X2(["å–œæ¬¢"])
        X3(["è‡ªç„¶"])
        X4(["è¯­è¨€"])
    end

    subgraph Forward["å‰å‘GRU (â†’) - ä»å·¦åˆ°å³"]
        direction LR
        F1(["hâƒ—â‚"])
        F2(["hâƒ—â‚‚"])
        F3(["hâƒ—â‚ƒ"])
        F4(["hâƒ—â‚„"])
        F1 --> F2 --> F3 --> F4
    end

    subgraph Backward["åå‘GRU (â†) - ä»å³åˆ°å·¦"]
        direction RL
        B1(["hâƒ–â‚"])
        B2(["hâƒ–â‚‚"])
        B3(["hâƒ–â‚ƒ"])
        B4(["hâƒ–â‚„"])
        B4 --> B3 --> B2 --> B1
    end

    subgraph Output["æœ€ç»ˆè¾“å‡ºï¼ˆæ‹¼æ¥ï¼‰"]
        direction LR
        H1(["hâ‚ = [hâƒ—â‚; hâƒ–â‚]"])
        H2(["hâ‚‚ = [hâƒ—â‚‚; hâƒ–â‚‚]"])
        H3(["hâ‚ƒ = [hâƒ—â‚ƒ; hâƒ–â‚ƒ]"])
        H4(["hâ‚„ = [hâƒ—â‚„; hâƒ–â‚„]"])
    end

    X1 --> F1
    X2 --> F2
    X3 --> F3
    X4 --> F4

    X1 --> B1
    X2 --> B2
    X3 --> B3
    X4 --> B4

    F1 --> H1
    B1 --> H1
    F2 --> H2
    B2 --> H2
    F3 --> H3
    B3 --> H3
    F4 --> H4
    B4 --> H4

    style X1 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style X2 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style X3 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style X4 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style F1 fill:#2ecc71,stroke:#333,stroke-width:2px
    style F2 fill:#2ecc71,stroke:#333,stroke-width:2px
    style F3 fill:#2ecc71,stroke:#333,stroke-width:2px
    style F4 fill:#2ecc71,stroke:#333,stroke-width:2px
    style B1 fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style B2 fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style B3 fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style B4 fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style H1 fill:#9b59b6,stroke:#333,stroke-width:2px,color:#fff
    style H2 fill:#9b59b6,stroke:#333,stroke-width:2px,color:#fff
    style H3 fill:#9b59b6,stroke:#333,stroke-width:2px,color:#fff
    style H4 fill:#9b59b6,stroke:#333,stroke-width:2px,color:#fff
```

**å›¾ä¾‹è¯´æ˜ï¼š**
- ğŸ”µ **è“è‰²è¾“å…¥**ï¼šè¯åµŒå…¥å‘é‡
- ğŸŸ¢ **ç»¿è‰² hâƒ—**ï¼šå‰å‘éšè—çŠ¶æ€ï¼ˆä»å·¦åˆ°å³ï¼Œæ•è·ä¸Šæ–‡ä¿¡æ¯ï¼‰
- ğŸ”´ **çº¢è‰² hâƒ–**ï¼šåå‘éšè—çŠ¶æ€ï¼ˆä»å³åˆ°å·¦ï¼Œæ•è·ä¸‹æ–‡ä¿¡æ¯ï¼‰
- ğŸŸ£ **ç´«è‰² h**ï¼šæœ€ç»ˆè¾“å‡ºï¼ˆå‰åå‘æ‹¼æ¥ï¼Œæ•è·å®Œæ•´ä¸Šä¸‹æ–‡ï¼‰

**æ ¸å¿ƒæ€æƒ³ï¼š** åŒæ—¶è¿è¡Œä¸¤ä¸ªGRUï¼Œä¸€ä¸ªæ­£å‘è¯»å–åºåˆ—ï¼Œä¸€ä¸ªåå‘è¯»å–åºåˆ—ï¼Œå°†ä¸¤è€…çš„éšè—çŠ¶æ€æ‹¼æ¥ï¼Œä½¿æ¯ä¸ªæ—¶åˆ»éƒ½èƒ½è·å¾—å®Œæ•´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯

---

**åŒå‘GRUçš„åº”ç”¨åœºæ™¯ï¼š**

| ä»»åŠ¡ | ä¸ºä»€ä¹ˆéœ€è¦åŒå‘ | ç¤ºä¾‹ |
|------|----------------|------|
| å‘½åå®ä½“è¯†åˆ« | ç¡®å®šå®ä½“è¾¹ç•Œéœ€è¦å‰åæ–‡ | "åŒ—äº¬å¤§å­¦"éœ€è¦çœ‹åˆ°"åŒ—äº¬"å’Œ"å¤§å­¦"æ‰èƒ½ç¡®å®šæ˜¯ORG |
| æƒ…æ„Ÿåˆ†æ | å¦å®šè¯å¯èƒ½åœ¨åé¢ | "è¿™éƒ¨ç”µå½±ä¸å·®"éœ€è¦çœ‹åˆ°"ä¸"å’Œ"å·®"æ‰èƒ½ç¡®å®šæƒ…æ„Ÿ |
| è¯æ€§æ ‡æ³¨ | è¯æ€§ä¾èµ–ä¸Šä¸‹æ–‡ | "record"å¯ä»¥æ˜¯åè¯æˆ–åŠ¨è¯ï¼Œéœ€è¦çœ‹å‰åè¯ç¡®å®š |
| æœºå™¨ç¿»è¯‘ | ç¿»è¯‘éœ€è¦å®Œæ•´ç†è§£å¥å­ | ç¿»è¯‘"ä»–å–œæ¬¢è‹¹æœ"æ—¶éœ€è¦çŸ¥é“"è‹¹æœ"æ˜¯æ°´æœè¿˜æ˜¯å…¬å¸ |

**ä¼˜åŠ¿ï¼š**
- æ•è·æ›´å®Œæ•´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
- æé«˜æ¨¡å‹æ€§èƒ½
- ç‰¹åˆ«é€‚åˆéœ€è¦å®Œæ•´å¥å­ç†è§£çš„ä»»åŠ¡

**å±€é™æ€§ï¼š**
- å¿…é¡»ç­‰æ•´ä¸ªåºåˆ—è¾“å…¥åæ‰èƒ½å¤„ç†ï¼ˆæ— æ³•åœ¨çº¿å¤„ç†ï¼‰
- è®¡ç®—é‡ç¿»å€

### 3.3.5 å¤šå±‚+åŒå‘ç»“æ„

**åŠ¨æœºï¼š** ç»“åˆå¤šå±‚ç»“æ„å’ŒåŒå‘ç»“æ„çš„ä¼˜åŠ¿ï¼ŒåŒæ—¶æ•è·å±‚æ¬¡åŒ–ç‰¹å¾å’Œå®Œæ•´ä¸Šä¸‹æ–‡ã€‚

**ç»“æ„è®¾è®¡ï¼š**

```mermaid
flowchart TB
    subgraph Input["è¾“å…¥å±‚ï¼ˆè¯åµŒå…¥ï¼‰"]
        direction LR
        X1(["xâ‚"])
        X2(["xâ‚‚"])
        X3(["xâ‚ƒ"])
        X4(["xâ‚„"])
        X1 --> X2 --> X3 --> X4
    end

    subgraph Layer1["ç¬¬1å±‚ åŒå‘GRU"]
        direction TB
        subgraph L1_F["å‰å‘ (â†’)"]
            direction LR
            H11F(["hâ‚â½Â¹â¾"]) --> H12F(["hâ‚‚â½Â¹â¾"]) --> H13F(["hâ‚ƒâ½Â¹â¾"]) --> H14F(["hâ‚„â½Â¹â¾"])
        end
        subgraph L1_B["åå‘ (â†)"]
            direction RL
            H14B(["hâ‚„â½Â¹â¾"]) --> H13B(["hâ‚ƒâ½Â¹â¾"]) --> H12B(["hâ‚‚â½Â¹â¾"]) --> H11B(["hâ‚â½Â¹â¾"])
        end
    end

    subgraph Layer2["ç¬¬2å±‚ åŒå‘GRU"]
        direction TB
        subgraph L2_F["å‰å‘ (â†’)"]
            direction LR
            H21F(["hâ‚â½Â²â¾"]) --> H22F(["hâ‚‚â½Â²â¾"]) --> H23F(["hâ‚ƒâ½Â²â¾"]) --> H24F(["hâ‚„â½Â²â¾"])
        end
        subgraph L2_B["åå‘ (â†)"]
            direction RL
            H24B(["hâ‚„â½Â²â¾"]) --> H23B(["hâ‚ƒâ½Â²â¾"]) --> H22B(["hâ‚‚â½Â²â¾"]) --> H21B(["hâ‚â½Â²â¾"])
        end
    end

    subgraph Layer3["ç¬¬3å±‚ åŒå‘GRU"]
        direction TB
        subgraph L3_F["å‰å‘ (â†’)"]
            direction LR
            H31F(["hâ‚â½Â³â¾"]) --> H32F(["hâ‚‚â½Â³â¾"]) --> H33F(["hâ‚ƒâ½Â³â¾"]) --> H34F(["hâ‚„â½Â³â¾"])
        end
        subgraph L3_B["åå‘ (â†)"]
            direction RL
            H34B(["hâ‚„â½Â³â¾"]) --> H33B(["hâ‚ƒâ½Â³â¾"]) --> H32B(["hâ‚‚â½Â³â¾"]) --> H31B(["hâ‚â½Â³â¾"])
        end
    end

    Input --> Layer1
    Layer1 --> Layer2
    Layer2 --> Layer3

    style X1 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style X2 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style X3 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style X4 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style H11F fill:#2ecc71,stroke:#333,stroke-width:2px
    style H12F fill:#2ecc71,stroke:#333,stroke-width:2px
    style H13F fill:#2ecc71,stroke:#333,stroke-width:2px
    style H14F fill:#2ecc71,stroke:#333,stroke-width:2px
    style H11B fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style H12B fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style H13B fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style H14B fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style H21F fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style H22F fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style H23F fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style H24F fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style H21B fill:#c0392b,stroke:#333,stroke-width:2px,color:#fff
    style H22B fill:#c0392b,stroke:#333,stroke-width:2px,color:#fff
    style H23B fill:#c0392b,stroke:#333,stroke-width:2px,color:#fff
    style H24B fill:#c0392b,stroke:#333,stroke-width:2px,color:#fff
    style H31F fill:#1e8449,stroke:#333,stroke-width:2px,color:#fff
    style H32F fill:#1e8449,stroke:#333,stroke-width:2px,color:#fff
    style H33F fill:#1e8449,stroke:#333,stroke-width:2px,color:#fff
    style H34F fill:#1e8449,stroke:#333,stroke-width:2px,color:#fff
    style H31B fill:#922b21,stroke:#333,stroke-width:2px,color:#fff
    style H32B fill:#922b21,stroke:#333,stroke-width:2px,color:#fff
    style H33B fill:#922b21,stroke:#333,stroke-width:2px,color:#fff
    style H34B fill:#922b21,stroke:#333,stroke-width:2px,color:#fff
```

**å›¾ä¾‹è¯´æ˜ï¼š**
- ğŸ”µ **è“è‰² x**ï¼šè¾“å…¥è¯åµŒå…¥
- ğŸŸ¢ **ç»¿è‰² hâƒ—**ï¼šå‰å‘éšè—çŠ¶æ€ï¼ˆæ¯å±‚é¢œè‰²æ·±æµ…é€’å¢ï¼‰
- ğŸ”´ **çº¢è‰² hâƒ–**ï¼šåå‘éšè—çŠ¶æ€ï¼ˆæ¯å±‚é¢œè‰²æ·±æµ…é€’å¢ï¼‰
- æ¯å±‚è¾“å‡º = [å‰å‘éšè—çŠ¶æ€ ; åå‘éšè—çŠ¶æ€] çš„æ‹¼æ¥

**æ¶æ„ä¼˜åŠ¿ï¼š**
1. **å‚ç›´æ–¹å‘**ï¼šå¤šå±‚å †å ï¼Œé€å±‚æŠ½è±¡ï¼ˆè¯çº§â†’çŸ­è¯­çº§â†’å¥å­çº§ï¼‰
2. **æ°´å¹³æ–¹å‘**ï¼šåŒå‘å¤„ç†ï¼Œæ•è·å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆä¸Šæ–‡+ä¸‹æ–‡ï¼‰

---

**å‚æ•°è®¡ç®—ï¼š**

å¦‚æœå•å±‚åŒå‘GRUçš„éšè—ç»´åº¦æ˜¯ `hidden_size`ï¼Œåˆ™ï¼š
- æ¯å±‚çš„è¾“å‡ºç»´åº¦ï¼š`hidden_size * 2`ï¼ˆå‰å‘+åå‘ï¼‰
- å‚æ•°é‡ï¼š`6 * hidden_size * (input_size + hidden_size)`ï¼ˆæ¯å±‚ä¸¤ä¸ªæ–¹å‘ï¼Œæ¯ä¸ªæ–¹å‘3ä¸ªé—¨ï¼‰

**PyTorchå®ç°ç¤ºä¾‹ï¼š**

```python
import torch
import torch.nn as nn

class MultiLayerBiGRU(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(MultiLayerBiGRU, self).__init__()
        
        self.num_layers = num_layers
        self.hidden_size = hidden_size
        
        # å¤šå±‚åŒå‘GRU
        self.gru = nn.GRU(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            bidirectional=True  # åŒå‘
        )
        
        # å…¨è¿æ¥å±‚ï¼ˆè¾“å…¥ç»´åº¦éœ€è¦è€ƒè™‘åŒå‘å’Œå±‚æ•°ï¼‰
        self.fc = nn.Linear(hidden_size * 2, output_size)
    
    def forward(self, x):
        # å‰å‘ä¼ æ’­
        out, _ = self.gru(x)
        
        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        out = out[:, -1, :]
        out = self.fc(out)
        return out

# æ¨¡å‹åˆå§‹åŒ–
model = MultiLayerBiGRU(
    input_size=100,      # è¯å‘é‡ç»´åº¦
    hidden_size=128,     # éšè—å±‚ç»´åº¦
    num_layers=3,        # å±‚æ•°
    output_size=2        # åˆ†ç±»æ•°
)
```

**å¤šå±‚åŒå‘GRUçš„åº”ç”¨ï¼š**
- å¤æ‚çš„æ–‡æœ¬åˆ†ç±»ä»»åŠ¡
- å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰
- æœºå™¨ç¿»è¯‘çš„ç¼–ç å™¨
- é—®ç­”ç³»ç»Ÿçš„ä¸Šä¸‹æ–‡ç†è§£

### 3.3.6 APIä½¿ç”¨

**PyTorch GRU APIï¼š**

```python
import torch
import torch.nn as nn

# åŸºæœ¬GRU
gru = nn.GRU(
    input_size=input_size,    # è¾“å…¥ç‰¹å¾ç»´åº¦
    hidden_size=hidden_size,  # éšè—å±‚ç»´åº¦
    num_layers=num_layers,    # å±‚æ•°
    bias=True,               # æ˜¯å¦ä½¿ç”¨åç½®
    batch_first=False,        # è¾“å…¥æ˜¯å¦ä¸º(batch, seq, feature)
    dropout=0,               # å±‚é—´dropoutæ¦‚ç‡ï¼ˆnum_layers>1æ—¶æœ‰æ•ˆï¼‰
    bidirectional=False       # æ˜¯å¦åŒå‘
)

# è¾“å…¥å½¢çŠ¶ï¼š(seq_len, batch_size, input_size)
# å¦‚æœbatch_first=Trueï¼Œåˆ™ä¸º(batch_size, seq_len, input_size)
input = torch.randn(10, 32, 100)  # 10ä¸ªæ—¶é—´æ­¥ï¼Œ32ä¸ªbatchï¼Œ100ç»´è¾“å…¥

# åˆå§‹éšè—çŠ¶æ€ï¼š(num_layers * num_directions, batch_size, hidden_size)
h0 = torch.randn(num_layers, 32, hidden_size)

# å‰å‘ä¼ æ’­
output, hn = gru(input, h0)
# outputå½¢çŠ¶ï¼š(seq_len, batch_size, num_directions * hidden_size)
# hnå½¢çŠ¶ï¼š(num_layers * num_directions, batch_size, hidden_size)
```

**å¸¸ç”¨å‚æ•°è¯´æ˜ï¼š**

| å‚æ•° | è¯´æ˜ | æ¨èå€¼ |
|------|------|--------|
| input_size | è¾“å…¥ç‰¹å¾ç»´åº¦ | è¯å‘é‡ç»´åº¦ï¼ˆå¦‚100, 300ï¼‰ |
| hidden_size | éšè—å±‚ç»´åº¦ | 64-512ï¼Œæ ¹æ®ä»»åŠ¡å¤æ‚åº¦ |
| num_layers | å±‚æ•° | 1-3å±‚ |
| batch_first | æ˜¯å¦ä»¥batchä¸ºç¬¬ä¸€ç»´åº¦ | Trueï¼ˆç¬¦åˆç›´è§‰ï¼‰ |
| bidirectional | æ˜¯å¦åŒå‘ | ä»»åŠ¡éœ€è¦å®Œæ•´ä¸Šä¸‹æ–‡æ—¶ä½¿ç”¨ |
| dropout | å±‚é—´dropout | 0.1-0.5ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰ |

**è¾“å…¥è¾“å‡ºå†…å®¹è¯¦è§£ï¼š**

| ç±»å‹ | å‚æ•° | è¯´æ˜ | å½¢çŠ¶ |
|------|------|------|------|
| **è¾“å…¥** | **input** | è¾“å…¥åºåˆ— | `(seq_len, batch_size, input_size)`ï¼Œå¦‚æœ `batch_first=True`ï¼Œåˆ™ä¸º `(batch_size, seq_len, input_size)` |
| | **h_0** | å¯é€‰ï¼Œåˆå§‹éšè—çŠ¶æ€ | `(num_layers Ã— num_directions, batch_size, hidden_size)` |
| **è¾“å‡º** | **output** | GRUå±‚çš„è¾“å‡ºï¼ŒåŒ…å«æœ€åä¸€å±‚æ¯ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ | `(seq_len, batch_size, num_directions Ã— hidden_size)`ï¼Œå¦‚æœ `batch_first=True`ï¼Œåˆ™ä¸º `(batch_size, seq_len, num_directions Ã— hidden_size)` |
| | **h_n** | æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼ŒåŒ…å«æ¯ä¸€å±‚çš„æ¯ä¸ªæ–¹å‘ | `(num_layers Ã— num_directions, batch_size, hidden_size)` |

**å½¢çŠ¶è¯¦è§£ç¤ºä¾‹ï¼š**

```python
import torch
import torch.nn as nn

# å‡è®¾å‚æ•°
batch_size = 32      # æ‰¹æ¬¡å¤§å°
seq_len = 10         # åºåˆ—é•¿åº¦
input_size = 100     # è¾“å…¥ç»´åº¦
hidden_size = 128    # éšè—å±‚ç»´åº¦
num_layers = 2       # å±‚æ•°
bidirectional = True # æ˜¯å¦åŒå‘

# è®¡ç®—æ–¹å‘æ•°
num_directions = 2 if bidirectional else 1

# åˆ›å»ºGRU
gru = nn.GRU(
    input_size=input_size,
    hidden_size=hidden_size,
    num_layers=num_layers,
    batch_first=True,  # æ‰¹æ¬¡ä¼˜å…ˆ
    bidirectional=bidirectional
)

# è¾“å…¥æ•°æ®
x = torch.randn(batch_size, seq_len, input_size)

# åˆå§‹éšè—çŠ¶æ€ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º0ï¼‰
h0 = torch.zeros(num_layers * num_directions, batch_size, hidden_size)

# å‰å‘ä¼ æ’­
output, hn = gru(x, h0)

print(f"è¾“å…¥ x å½¢çŠ¶:        {x.shape}")      # [32, 10, 100]
print(f"åˆå§‹çŠ¶æ€ h0 å½¢çŠ¶:    {h0.shape}")    # [4, 32, 128]  (2å±‚Ã—2æ–¹å‘)
print(f"è¾“å‡º output å½¢çŠ¶:    {output.shape}") # [32, 10, 256] (128Ã—2æ–¹å‘)
print(f"æœ€ç»ˆçŠ¶æ€ hn å½¢çŠ¶:    {hn.shape}")    # [4, 32, 128]  (2å±‚Ã—2æ–¹å‘)
```

**è¾“å‡ºè§£æï¼š**

```mermaid
flowchart TB
    subgraph OutputParse["è¾“å‡ºè§£æ"]
        direction TB

        %% output è§£æ
        OutputTitle["output åŒ…å«æ¯ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼š"]
        Output1["output[:, 0, :] â†’ ç¬¬1ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼ˆæ‰€æœ‰batchï¼‰"]
        Output2["output[:, 1, :] â†’ ç¬¬2ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼ˆæ‰€æœ‰batchï¼‰"]
        OutputDot["..."]
        OutputLast["output[:, -1, :] â†’ æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼ˆæ‰€æœ‰batchï¼‰"]

        %% hn è§£æ
        HnTitle["hn åŒ…å«æ¯å±‚çš„æœ€ç»ˆéšè—çŠ¶æ€ï¼š"]
        Hn1["hn[0] â†’ ç¬¬1å±‚å‰å‘çš„æœ€ç»ˆçŠ¶æ€"]
        Hn2["hn[1] â†’ ç¬¬1å±‚åå‘çš„æœ€ç»ˆçŠ¶æ€ï¼ˆå¦‚æœåŒå‘ï¼‰"]
        Hn3["hn[2] â†’ ç¬¬2å±‚å‰å‘çš„æœ€ç»ˆçŠ¶æ€"]
        Hn4["hn[3] â†’ ç¬¬2å±‚åå‘çš„æœ€ç»ˆçŠ¶æ€ï¼ˆå¦‚æœåŒå‘ï¼‰"]

        %% è¿æ¥
        OutputTitle --> Output1 --> Output2 --> OutputDot --> OutputLast --> HnTitle --> Hn1 --> Hn2 --> Hn3 --> Hn4
    end

    style OutputParse fill:#f0f8ff,stroke:#333,stroke-width:2px
    style OutputTitle fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style HnTitle fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style Output1 fill:#27ae60,stroke:#333,stroke-width:2px
    style Output2 fill:#27ae60,stroke:#333,stroke-width:2px
    style OutputLast fill:#27ae60,stroke:#333,stroke-width:2px
    style Hn1 fill:#f39c12,stroke:#333,stroke-width:2px
    style Hn2 fill:#f39c12,stroke:#333,stroke-width:2px
    style Hn3 fill:#f39c12,stroke:#333,stroke-width:2px
    style Hn4 fill:#f39c12,stroke:#333,stroke-width:2px
```

### 3.3.7 æ¡ˆä¾‹å®æ“ï¼ˆAIæ™ºè¯„V2.0ï¼‰

#### é¡¹ç›®æ¦‚è¿°

æœ¬æ¡ˆä¾‹å®ç°ä¸€ä¸ªåŸºäºGRUçš„ä¸­æ–‡è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿï¼ˆAIæ™ºè¯„V2.0ï¼‰ï¼Œèƒ½å¤Ÿè‡ªåŠ¨åˆ¤æ–­ç”¨æˆ·è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘ï¼ˆæ­£å‘/è´Ÿå‘ï¼‰ã€‚é¡¹ç›®å®Œæ•´ä»£ç ä½äº `review_analyze_gru` ç›®å½•ä¸‹ã€‚

#### æ ¸å¿ƒæ€è·¯

**ä»»åŠ¡å®šä¹‰ï¼š** ç»™å®šä¸€æ¡è¯„è®ºæ–‡æœ¬ï¼Œé¢„æµ‹å…¶æƒ…æ„Ÿå€¾å‘ï¼ˆ0=è´Ÿå‘ï¼Œ1=æ­£å‘ï¼‰

```
è¾“å…¥æ–‡æœ¬ï¼š"è¿™æ¬¾æ‰‹æœºçœŸçš„å¤ªå¥½ç”¨äº†ï¼Œå¼ºçƒˆæ¨èï¼"
æ¨¡å‹è¾“å‡ºï¼šæ­£å‘æƒ…æ„Ÿï¼ˆæ¦‚ç‡ï¼š0.91ï¼‰

å¤„ç†æµç¨‹ï¼š
1. åˆ†è¯ï¼š["è¿™æ¬¾", "æ‰‹æœº", "çœŸçš„", "å¤ªå¥½ç”¨", "äº†", "ï¼Œ", "å¼ºçƒˆ", "æ¨è", "ï¼"]
2. ç¼–ç ï¼š[45, 892, 123, 567, 8, 2, 234, 789, 3]
3. GRUç¼–ç  â†’ æå–ç‰¹å¾
4. åˆ†ç±»ï¼šæ­£å‘ï¼ˆæ¦‚ç‡>0.5ï¼‰
```

#### é¡¹ç›®ç»“æ„

```
review_analyze_gru/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py      # é…ç½®æ–‡ä»¶ï¼ˆè·¯å¾„ã€è¶…å‚æ•°ï¼‰
â”‚   â”œâ”€â”€ process.py     # æ•°æ®é¢„å¤„ç†ï¼ˆæ¸…æ´—ã€åˆ†è¯ã€ç¼–ç ã€åˆ’åˆ†ï¼‰
â”‚   â”œâ”€â”€ dataset.py     # Datasetç±»å’ŒDataLoader
â”‚   â”œâ”€â”€ model.py       # GRUæ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ train.py       # è®­ç»ƒæµç¨‹
â”‚   â”œâ”€â”€ evaluate.py    # æ¨¡å‹è¯„ä¼°
â”‚   â”œâ”€â”€ predict.py     # é¢„æµ‹æ¥å£
â”‚   â””â”€â”€ tokenizer.py   # åˆ†è¯å™¨å®ç°
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/           # åŸå§‹è¯„è®ºæ•°æ®
â”‚   â””â”€â”€ processed/     # å¤„ç†åçš„è®­ç»ƒ/æµ‹è¯•é›†
â”œâ”€â”€ models/            # ä¿å­˜çš„è¯è¡¨å’Œæ¨¡å‹æƒé‡
â””â”€â”€ logs/              # TensorBoardæ—¥å¿—
```

#### è¯¦ç»†å®ç°

> **ã€ä¸RNN/LSTMæ¡ˆä¾‹çš„å¯¹æ¯”è¯´æ˜ã€‘**
> 
> æœ¬æ¡ˆä¾‹ä¸RNNã€LSTMæ¡ˆä¾‹ç›¸æ¯”ï¼Œæœ‰ä»¥ä¸‹æ ¸å¿ƒå·®å¼‚ï¼š
> 
> | å¯¹æ¯”ç»´åº¦ | RNNæ¡ˆä¾‹ | LSTMæ¡ˆä¾‹ | GRUæ¡ˆä¾‹ï¼ˆæœ¬æ¡ˆä¾‹ï¼‰ |
> |----------|---------|----------|------------------|
> | **ä»»åŠ¡ç±»å‹** | å¤šåˆ†ç±»ï¼ˆé¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼‰ | äºŒåˆ†ç±»ï¼ˆæƒ…æ„Ÿåˆ†æï¼‰ | äºŒåˆ†ç±»ï¼ˆæƒ…æ„Ÿåˆ†æï¼‰ |
> | **è¾“å‡ºç»´åº¦** | vocab_size | 1 | 1 |
> | **æ¨¡å‹ç»“æ„** | `nn.RNN` | `nn.LSTM`ï¼ˆ3é—¨+ç»†èƒçŠ¶æ€ï¼‰ | `nn.GRU`ï¼ˆ2é—¨ï¼Œæ— ç»†èƒçŠ¶æ€ï¼‰ |
> | **çŠ¶æ€æ•°é‡** | 1ä¸ªï¼ˆhiddenï¼‰ | 2ä¸ªï¼ˆhidden+cellï¼‰ | 1ä¸ªï¼ˆhiddenï¼‰ |
> | **å‚æ•°é‡** | åŸºå‡† | çº¦4Ã—RNN | çº¦3Ã—RNNï¼ˆæ¯”LSTMå°‘25%ï¼‰ |
> | **æŸå¤±å‡½æ•°** | `CrossEntropyLoss` | `BCEWithLogitsLoss` | `BCEWithLogitsLoss` |
> | **å‰å‘ä¼ æ’­è¿”å›å€¼** | `output, hidden` | `output, (hidden, cell)` | `output, hidden`ï¼ˆåŒRNNï¼‰ |
> 
> **GRU vs LSTM æ ¸å¿ƒå·®å¼‚ï¼š**
> - **é—¨æ§æ•°é‡**ï¼šLSTMæœ‰3ä¸ªé—¨ï¼ˆé—å¿˜ã€è¾“å…¥ã€è¾“å‡ºï¼‰ï¼ŒGRUæœ‰2ä¸ªé—¨ï¼ˆæ›´æ–°ã€é‡ç½®ï¼‰
> - **ç»†èƒçŠ¶æ€**ï¼šLSTMæœ‰ç‹¬ç«‹çš„ç»†èƒçŠ¶æ€Câ‚œï¼ŒGRUå°†ç»†èƒçŠ¶æ€åˆå¹¶åˆ°éšè—çŠ¶æ€ä¸­
> - **å‰å‘ä¼ æ’­è¿”å›å€¼**ï¼šGRUåŒRNNè¿”å› `(output, hidden)`ï¼ŒLSTMè¿”å› `(output, (hidden, cell))`
> 
> ä»¥ä¸‹ä»£ç ä¸­ï¼Œ**ã€ä¸LSTMå·®å¼‚ã€‘** æ ‡è®°è¡¨ç¤ºä¸LSTMæ¡ˆä¾‹ä¸åŒçš„éƒ¨åˆ†ã€‚

**1. æ¨¡å‹å®šä¹‰ï¼ˆmodel.pyï¼‰**

```python
"""
æ¨¡å‹å®šä¹‰æ¨¡å—

åŠŸèƒ½æè¿°:
    æœ¬æ¨¡å—å®šä¹‰äº†åŸºäºGRUçš„æƒ…æ„Ÿåˆ†ææ¨¡å‹ReviewAnalyzeModelã€‚
    æ¨¡å‹ç»“æ„ï¼šEmbeddingå±‚ -> GRUå±‚ -> Linearå±‚
    æ”¯æŒå˜é•¿åºåˆ—å¤„ç†ï¼Œé€šè¿‡æå–æœ€åä¸€ä¸ªæœ‰æ•ˆæ—¶é—´æ­¥çš„éšè—çŠ¶æ€è¿›è¡Œåˆ†ç±»ã€‚

ä½œè€…: Red_Moon
åˆ›å»ºæ—¥æœŸ: 2026-02
"""

import torch.nn as nn
import config
import torch


class ReviewAnalyzeModel(nn.Module):
    """
    ã€ä¸LSTMå·®å¼‚ã€‘åŸºäºGRUçš„è¯„è®ºæƒ…æ„Ÿåˆ†ææ¨¡å‹

    æ¶æ„è¯´æ˜:
        1. Embeddingå±‚: å°†è¯ç´¢å¼•æ˜ å°„ä¸ºç¨ å¯†å‘é‡è¡¨ç¤º
        2. GRUå±‚: å»ºæ¨¡åºåˆ—çš„æ—¶åºä¾èµ–å…³ç³»ï¼Œæ•è·ä¸Šä¸‹æ–‡ä¿¡æ¯
           ã€ä¸LSTMå·®å¼‚ã€‘ä½¿ç”¨nn.GRUæ›¿ä»£nn.LSTMï¼Œé—¨æ§ä»3ä¸ªå‡å°‘åˆ°2ä¸ª
           ã€ä¸LSTMå·®å¼‚ã€‘æ— ç»†èƒçŠ¶æ€ï¼Œå‚æ•°é‡å‡å°‘çº¦25%
        3. Linearå±‚: å°†GRUæœ€ç»ˆéšè—çŠ¶æ€æ˜ å°„åˆ°è¾“å‡ºç©ºé—´
    """

    def __init__(self, vocab_size, padding_index):
        """
        åˆå§‹åŒ–æ¨¡å‹

        å‚æ•°:
            vocab_size (int): è¯è¡¨å¤§å°ï¼Œå†³å®šEmbeddingå±‚çš„è¾“å…¥ç»´åº¦
            padding_index (int): å¡«å……æ ‡è®°<pad>çš„ç´¢å¼•ï¼Œç”¨äºå¤„ç†å˜é•¿åºåˆ—
        """
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, config.EMBEDDING_DIM, padding_idx=padding_index)
        # ã€ä¸LSTMå·®å¼‚ã€‘ä½¿ç”¨nn.GRUæ›¿ä»£nn.LSTM
        # GRUåªæœ‰æ›´æ–°é—¨å’Œé‡ç½®é—¨ï¼Œæ— ç»†èƒçŠ¶æ€ï¼Œå‚æ•°é‡æ›´å°‘
        self.gru = nn.GRU(input_size=config.EMBEDDING_DIM, hidden_size=config.HIDDEN_SIZE, batch_first=True)
        self.linear = nn.Linear(config.HIDDEN_SIZE, 1)

    def forward(self, x: torch.Tensor):
        """
        å‰å‘ä¼ æ’­

        å‚æ•°:
            x (torch.Tensor): è¾“å…¥è¯ç´¢å¼•åºåˆ—ï¼Œå½¢çŠ¶ä¸º[batch_size, seq_len]

        è¿”å›:
            torch.Tensor: æƒ…æ„Ÿé¢„æµ‹logitsï¼Œå½¢çŠ¶ä¸º[batch_size]
        """
        # x.shape : [batch_size, seq_len]
        embed = self.embedding(x)
        # embed.shape : [batch_size, seq_len, embedding_dim]
        # ã€ä¸LSTMå·®å¼‚ã€‘GRUè¿”å›(output, hidden)ï¼ŒLSTMè¿”å›(output, (hidden, cell))
        # ã€ä¸RNNç›¸åŒã€‘GRUçš„å‰å‘ä¼ æ’­è¿”å›å€¼ä¸RNNä¸€è‡´
        gru_out, _ = self.gru(embed)
        # gru_out.shape : [batch_size, seq_len, hidden_size]
        # ã€åŒLSTMã€‘å¤„ç†å˜é•¿åºåˆ—ï¼šé€šè¿‡padding_idxæ‰¾åˆ°æ¯ä¸ªåºåˆ—çš„å®é™…é•¿åº¦
        batch_indexes = torch.arange(0, gru_out.shape[0])
        lengths = (x != self.embedding.padding_idx).sum(dim=1)
        last_hidden = gru_out[batch_indexes, lengths - 1]
        # last_hidden.shape : [batch_size, hidden_size]
        out = self.linear(last_hidden).squeeze(-1)
        # out.shape : [batch_size]
        return out
```

**2. è®­ç»ƒæµç¨‹ï¼ˆtrain.pyï¼‰**

```python
"""
æ¨¡å‹è®­ç»ƒæ¨¡å—

åŠŸèƒ½æè¿°:
    æœ¬æ¨¡å—å®ç°äº†åŸºäºGRUçš„æƒ…æ„Ÿåˆ†ææ¨¡å‹çš„å®Œæ•´è®­ç»ƒæµç¨‹ã€‚

ä½œè€…: Red_Moon
åˆ›å»ºæ—¥æœŸ: 2026-02
"""

import time
from tqdm import tqdm
import torch
import torch.nn as nn
from dataset import get_dataloader
from model import ReviewAnalyzeModel
from tokenizer import JiebaTokenizer
import config
from torch.utils.tensorboard import SummaryWriter


def train_one_epoch(model, dataloader, loss_fn, optimizer, device):
    """
    è®­ç»ƒä¸€ä¸ªepoch
    """
    model.train()
    total_loss = 0
    for inputs, targets in tqdm(dataloader):
        inputs, targets = inputs.to(device), targets.to(device)
        outputs = model(inputs)
        loss = loss_fn(outputs, targets)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(dataloader)


def train():
    """
    å®Œæ•´çš„æ¨¡å‹è®­ç»ƒæµç¨‹
    """
    # 1. è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # 2. æ•°æ®
    dataloader = get_dataloader()
    # 3. åˆ†è¯å™¨
    tokenizer = JiebaTokenizer.from_vocab(config.MODELS_DIR / "vocab.txt")
    # 4. æ¨¡å‹
    # ã€ä¸LSTMå·®å¼‚ã€‘ä½¿ç”¨ReviewAnalyzeModelï¼ˆå†…éƒ¨ä½¿ç”¨GRUè€ŒéLSTMï¼‰
    model = ReviewAnalyzeModel(vocab_size=tokenizer.vocab_size, 
                               padding_index=tokenizer.pad_token_index).to(device)
    # 5. æŸå¤±å‡½æ•°ï¼ˆåŒLSTMï¼šäºŒåˆ†ç±»ä½¿ç”¨BCEWithLogitsLossï¼‰
    loss_fn = torch.nn.BCEWithLogitsLoss()
    # 6. ä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE)
    # 7. TensorBoard Writer
    writer = SummaryWriter(log_dir=config.LOGS_DIR / time.strftime('%Y-%m-%d_%H-%M-%S'))

    best_loss = float('inf')
    for epoch in range(1, config.EPOCHS + 1):
        print(f'======= Epoch {epoch} =======')
        loss = train_one_epoch(model, dataloader, loss_fn, optimizer, device)
        print(f'loss:{loss:.4f}')
        writer.add_scalar('loss', loss, epoch)
        if loss < best_loss:
            best_loss = loss
            torch.save(model.state_dict(), config.MODELS_DIR / 'best.pt')
            print("ä¿å­˜æ¨¡å‹")
    writer.close()
```

**3. é¢„æµ‹æ¥å£ï¼ˆpredict.pyï¼‰**

```python
"""
æ¨¡å‹é¢„æµ‹æ¨¡å—

åŠŸèƒ½æè¿°:
    æœ¬æ¨¡å—å®ç°äº†åŸºäºGRUçš„æƒ…æ„Ÿåˆ†ææ¨¡å‹çš„é¢„æµ‹åŠŸèƒ½ã€‚
    æ”¯æŒæ‰¹é‡é¢„æµ‹å’Œå•æ¡æ–‡æœ¬é¢„æµ‹ï¼Œæä¾›äº¤äº’å¼å‘½ä»¤è¡Œç•Œé¢ã€‚

ä½œè€…: Red_Moon
åˆ›å»ºæ—¥æœŸ: 2026-02
"""

import torch
import config
from model import ReviewAnalyzeModel
from tokenizer import JiebaTokenizer


def predict_batch(model, inputs):
    """
    æ‰¹é‡é¢„æµ‹
    """
    model.eval()
    with torch.no_grad():
        output = model(inputs)
    # ã€åŒLSTMã€‘äºŒåˆ†ç±»ä½¿ç”¨sigmoidè·å–æ¦‚ç‡
    batch_result = torch.sigmoid(output)
    return batch_result.tolist()


def predict(text, model, tokenizer, device):
    """
    å•æ¡æ–‡æœ¬é¢„æµ‹
    """
    indexes = tokenizer.encode(text, seq_len=config.SEQ_LEN)
    input_tensor = torch.tensor([indexes], dtype=torch.long).to(device)
    batch_result = predict_batch(model, input_tensor)
    return batch_result[0]


def run_predict():
    """
    è¿è¡Œäº¤äº’å¼é¢„æµ‹ç•Œé¢
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    tokenizer = JiebaTokenizer.from_vocab(config.MODELS_DIR / 'vocab.txt')
    print("è¯è¡¨åŠ è½½æˆåŠŸ")

    # ã€ä¸LSTMå·®å¼‚ã€‘ä½¿ç”¨GRUç‰ˆæœ¬çš„ReviewAnalyzeModel
    model = ReviewAnalyzeModel(vocab_size=tokenizer.vocab_size, 
                               padding_index=tokenizer.pad_token_index).to(device)
    model.load_state_dict(torch.load(config.MODELS_DIR / 'best.pt'))
    print("æ¨¡å‹åŠ è½½æˆåŠŸ")

    print("\n" + "=" * 40)
    print("æ¬¢è¿ä½¿ç”¨æƒ…æ„Ÿåˆ†ææ¨¡å‹(è¾“å…¥qæˆ–è€…quité€€å‡º)")
    print("=" * 40)

    while True:
        user_input = input("> ")
        if user_input in ['q', 'quit']:
            print("æ¬¢è¿ä¸‹æ¬¡å†æ¥")
            break
        if user_input.strip() == '':
            print("è¯·è¾“å…¥å†…å®¹")
            continue

        result = predict(user_input, model, tokenizer, device)
        print(f'é¢„æµ‹ç»“æœ: {result}')
        # ã€åŒLSTMã€‘äºŒåˆ†ç±»ç»“æœè§£é‡Šï¼ˆ>0.5ä¸ºæ­£ï¼Œ<0.5ä¸ºè´Ÿï¼‰
        if result > 0.5:
            print(f"æ­£å‘è¯„è®º,ç½®ä¿¡åº¦:{result}")
        else:
            print(f"è´Ÿå‘è¯„è®º,ç½®ä¿¡åº¦:{1-result}")
        print("-" * 40)
```

---

**ã€ä¸‰æ¨¡å‹æ¡ˆä¾‹ä»£ç å¯¹æ¯”æ€»ç»“ã€‘**

```mermaid
flowchart TB
    subgraph Comparison["RNN vs LSTM vs GRU æ¡ˆä¾‹ä»£ç å¯¹æ¯”"]
        direction TB
        
        subgraph Task["ä»»åŠ¡ç±»å‹"]
            RNN_Task["RNN: å¤šåˆ†ç±»<br/>é¢„æµ‹ä¸‹ä¸€ä¸ªè¯"]
            LSTM_Task["LSTM: äºŒåˆ†ç±»<br/>æƒ…æ„Ÿåˆ†æ"]
            GRU_Task["GRU: äºŒåˆ†ç±»<br/>æƒ…æ„Ÿåˆ†æ"]
        end
        
        subgraph ModelStruct["æ¨¡å‹ç»“æ„å·®å¼‚"]
            RNN_Struct["nn.RNN<br/>è¿”å›: output, hidden"]
            LSTM_Struct["nn.LSTM<br/>è¿”å›: output, hidden, cell<br/>3ä¸ªé—¨æ§ + ç»†èƒçŠ¶æ€"]
            GRU_Struct["nn.GRU<br/>è¿”å›: output, hidden<br/>2ä¸ªé—¨æ§ï¼Œæ— ç»†èƒçŠ¶æ€"]
        end
        
        subgraph Loss["æŸå¤±å‡½æ•°"]
            RNN_Loss["CrossEntropyLoss<br/>å¤šåˆ†ç±»äº¤å‰ç†µ"]
            LSTM_Loss["BCEWithLogitsLoss<br/>äºŒåˆ†ç±»äº¤å‰ç†µ"]
            GRU_Loss["BCEWithLogitsLoss<br/>äºŒåˆ†ç±»äº¤å‰ç†µ"]
        end
        
        subgraph Output["è¾“å‡ºå¤„ç†"]
            RNN_Out["output[:, -1, :]<br/>å›ºå®šé•¿åº¦å–æœ€å"]
            LSTM_Out["batch_indexes, lengths-1<br/>å˜é•¿åºåˆ—å¤„ç†"]
            GRU_Out["batch_indexes, lengths-1<br/>å˜é•¿åºåˆ—å¤„ç†"]
        end
        
        subgraph Predict["é¢„æµ‹è¾“å‡º"]
            RNN_Pred["softmax + topk<br/>è¿”å›Top-Kå€™é€‰è¯"]
            LSTM_Pred["sigmoid<br/>è¿”å›æ­£/è´Ÿå‘æ¦‚ç‡"]
            GRU_Pred["sigmoid<br/>è¿”å›æ­£/è´Ÿå‘æ¦‚ç‡"]
        end
    end
    
    style RNN_Task fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style LSTM_Task fill:#9b59b6,stroke:#333,stroke-width:2px,color:#fff
    style GRU_Task fill:#e67e22,stroke:#333,stroke-width:2px,color:#fff
    style RNN_Struct fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style LSTM_Struct fill:#9b59b6,stroke:#333,stroke-width:2px,color:#fff
    style GRU_Struct fill:#e67e22,stroke:#333,stroke-width:2px,color:#fff
```

#### è¿è¡Œç¤ºä¾‹

```bash
# 1. æ•°æ®é¢„å¤„ç†
python src/process.py

# 2. è®­ç»ƒæ¨¡å‹
python src/train.py

# 3. è¯„ä¼°æ¨¡å‹
python src/evaluate.py

# 4. äº¤äº’å¼é¢„æµ‹
python src/predict.py
```

é¢„æµ‹æ•ˆæœï¼š
```
ä½¿ç”¨è®¾å¤‡: cuda
è¯è¡¨åŠ è½½æˆåŠŸ
æ¨¡å‹åŠ è½½æˆåŠŸ

========================================
æ¬¢è¿ä½¿ç”¨æƒ…æ„Ÿåˆ†ææ¨¡å‹(è¾“å…¥qæˆ–è€…quité€€å‡º)
========================================
> è¿™æ¬¾æ‰‹æœºè´¨é‡å¤ªå·®äº†ï¼Œå®Œå…¨ä¸å€¼è¿™ä¸ªä»·
é¢„æµ‹ç»“æœ: 0.15
è´Ÿå‘è¯„è®º,ç½®ä¿¡åº¦:0.85
----------------------------------------
> éå¸¸æ»¡æ„ï¼Œç‰©æµå¾ˆå¿«ï¼Œå•†å“è´¨é‡å¾ˆå¥½
é¢„æµ‹ç»“æœ: 0.89
æ­£å‘è¯„è®º,ç½®ä¿¡åº¦:0.89
```

### 3.3.8 å­˜åœ¨é—®é¢˜

**1. è¡¨è¾¾èƒ½åŠ›é™åˆ¶**

GRUç›¸æ¯”LSTMå°‘äº†ä¸€ä¸ªè¾“å‡ºé—¨ï¼Œè¿™å¯¼è‡´ï¼š
- æ— æ³•åƒLSTMé‚£æ ·ç²¾ç»†æ§åˆ¶è¾“å‡ºå†…å®¹
- åœ¨æŸäº›å¤æ‚ä»»åŠ¡ä¸Šæ€§èƒ½ç•¥é€ŠäºLSTM
- å¯¹äºéœ€è¦ç²¾ç¡®è®°å¿†æ§åˆ¶çš„ä»»åŠ¡ï¼ˆå¦‚å¤æ‚æ¨ç†ï¼‰è¡¨ç°ä¸ä½³

**2. é•¿æœŸä¾èµ–çš„æƒè¡¡**

è™½ç„¶GRUä¹Ÿèƒ½è§£å†³é•¿æœŸä¾èµ–é—®é¢˜ï¼Œä½†ç›¸æ¯”LSTMï¼š
- æ›´æ–°é—¨åŒæ—¶æ§åˆ¶é—å¿˜å’Œè¾“å…¥ï¼Œçµæ´»æ€§è¾ƒä½
- åœ¨æŸäº›è¶…é•¿åºåˆ—ä»»åŠ¡ä¸Šï¼Œæ•ˆæœä¸å¦‚LSTMç¨³å®š

**3. é€‚ç”¨åœºæ™¯é™åˆ¶**

| åœºæ™¯ | æ¨èæ¨¡å‹ | åŸå›  |
|------|----------|------|
| ç®€å•æ–‡æœ¬åˆ†ç±» | GRU | å‚æ•°å°‘ï¼Œè®­ç»ƒå¿« |
| å¤æ‚æœºå™¨ç¿»è¯‘ | LSTM | è¡¨è¾¾èƒ½åŠ›æ›´å¼º |
| èµ„æºå—é™ç¯å¢ƒ | GRU | è®¡ç®—æ•ˆç‡é«˜ |
| éœ€è¦ç²¾ç¡®æ§åˆ¶ | LSTM | é—¨æ§æ›´ç²¾ç»† |

---

## LSTM vs GRU è¯¦ç»†å¯¹æ¯”

| ç‰¹æ€§ | LSTM | GRU |
|------|------|-----|
| é—¨æ§æ•°é‡ | 3ä¸ªï¼ˆé—å¿˜ã€è¾“å…¥ã€è¾“å‡ºï¼‰ | 2ä¸ªï¼ˆæ›´æ–°ã€é‡ç½®ï¼‰ |
| çŠ¶æ€æ•°é‡ | 2ä¸ªï¼ˆç»†èƒçŠ¶æ€+éšè—çŠ¶æ€ï¼‰ | 1ä¸ªï¼ˆéšè—çŠ¶æ€ï¼‰ |
| å‚æ•°æ•°é‡ | è¾ƒå¤š | è¾ƒå°‘ï¼ˆçº¦25%å‡å°‘ï¼‰ |
| è®­ç»ƒé€Ÿåº¦ | è¾ƒæ…¢ | è¾ƒå¿« |
| è¡¨è¾¾èƒ½åŠ› | æ›´å¼º | ç¨å¼±ä½†é€šå¸¸è¶³å¤Ÿ |
| é€‚ç”¨åœºæ™¯ | å¤æ‚ä»»åŠ¡ã€é•¿åºåˆ— | ä¸­ç­‰å¤æ‚åº¦ä»»åŠ¡ |

**é€‰æ‹©å»ºè®®ï¼š**
- æ•°æ®é‡å°ï¼šGRUï¼ˆå‚æ•°å°‘ï¼Œä¸æ˜“è¿‡æ‹Ÿåˆï¼‰
- æ•°æ®é‡å¤§ï¼šLSTMï¼ˆè¡¨è¾¾èƒ½åŠ›æ›´å¼ºï¼‰
- å®é™…åº”ç”¨ä¸­ä¸¤è€…æ€§èƒ½å·®å¼‚é€šå¸¸ä¸å¤§

---

## ç›¸å…³æ–‡æ¡£

- [RNNï¼ˆå¾ªç¯ç¥ç»ç½‘ç»œï¼‰](./03_RNN.md) - GRUçš„åŸºç¡€ç‰ˆæœ¬
- [LSTMï¼ˆé•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼‰](./03_LSTM.md) - GRUçš„å®Œæ•´ç‰ˆæœ¬ï¼Œè¡¨è¾¾èƒ½åŠ›æ›´å¼º

---

## å‚è€ƒèµ„æº

- PyTorchå®˜æ–¹æ–‡æ¡£ï¼šhttps://pytorch.org/docs/stable/nn.html#gru
- ç»å…¸è®ºæ–‡ï¼š
  - GRU: "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation" (2014) - Cho et al.
