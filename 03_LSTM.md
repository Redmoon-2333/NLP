## 3.2 LSTMï¼ˆé•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼‰

### 3.2.1 æ¦‚è¿°

**é—®é¢˜æ ¹æºï¼š**

ä¼ ç»ŸRNNåœ¨å¤„ç†é•¿åºåˆ—æ—¶ï¼Œç”±äºæ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œå‰é¢æ—¶åˆ»çš„ä¿¡æ¯éš¾ä»¥ä¼ é€’åˆ°åé¢ã€‚è¿™å¯¼è‡´RNNåªèƒ½æœ‰æ•ˆæ•æ‰çŸ­è·ç¦»çš„ä¾èµ–å…³ç³»ï¼Œè€Œæ— æ³•å»ºç«‹é•¿è·ç¦»çš„è®°å¿†ã€‚

**LSTMçš„è§£å†³æ–¹æ¡ˆï¼š**

1997å¹´ï¼ŒHochreiterå’ŒSchmidhuberæå‡ºäº†é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLong Short-Term Memoryï¼ŒLSTMï¼‰ï¼Œä¸“é—¨è®¾è®¡ç”¨äºè§£å†³RNNçš„é•¿æœŸä¾èµ–é—®é¢˜ã€‚

**æ ¸å¿ƒåˆ›æ–°ï¼š**

LSTMå¼•å…¥äº†"ç»†èƒçŠ¶æ€"ï¼ˆCell Stateï¼‰å’Œ"é—¨æ§æœºåˆ¶"ï¼ˆGating Mechanismï¼‰ï¼š
- **ç»†èƒçŠ¶æ€**ï¼šåƒä¸€æ¡ä¼ é€å¸¦ï¼Œä¿¡æ¯å¯ä»¥åœ¨ä¸Šé¢ç›¸å¯¹ unchanged åœ°æµåŠ¨
- **é—¨æ§æœºåˆ¶**ï¼šé€šè¿‡å¯å­¦ä¹ çš„é—¨æ¥æ§åˆ¶ä¿¡æ¯çš„æµåŠ¨ï¼Œå†³å®šå“ªäº›ä¿¡æ¯åº”è¯¥ä¿ç•™ã€ä¸¢å¼ƒæˆ–è¾“å‡º

**ä¸ºä»€ä¹ˆå«"é•¿çŸ­æœŸè®°å¿†"ï¼Ÿ**

**é•¿çŸ­è®°å¿†æœºåˆ¶ï¼š**

- **çŸ­æœŸè®°å¿†ï¼ˆShort-termï¼‰ï¼šéšè—çŠ¶æ€ hâ‚œ**
  - ç±»ä¼¼RNNçš„éšè—çŠ¶æ€
  - æºå¸¦å½“å‰æ—¶åˆ»çš„ä¸Šä¸‹æ–‡ä¿¡æ¯

- **é•¿æœŸè®°å¿†ï¼ˆLong-termï¼‰ï¼šç»†èƒçŠ¶æ€ Câ‚œ**
  - è´¯ç©¿æ•´ä¸ªåºåˆ—çš„ä¿¡æ¯é€šé“
  - å¯ä»¥é€‰æ‹©æ€§åœ°ä¿ç•™æˆ–é—å¿˜å†å²ä¿¡æ¯

- **é—¨æ§æœºåˆ¶**ï¼šæ§åˆ¶ä¿¡æ¯åœ¨é•¿çŸ­è®°å¿†ä¹‹é—´çš„æµåŠ¨

### 3.2.2 åŸºç¡€ç»“æ„

LSTMçš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªç²¾å¿ƒè®¾è®¡çš„è®°å¿†å•å…ƒï¼ŒåŒ…å«ä¸‰æ¡ä¿¡æ¯æµå’Œä¸‰ä¸ªé—¨æ§æœºåˆ¶ã€‚

**ç»“æ„å±•å¼€å›¾ï¼š**

```mermaid
flowchart LR
    subgraph Time_Step_1["t=1"]
        X1(["xâ‚"])
        LSTM1["LSTM Cell"]
        H1(["hâ‚"])
        C1(["Câ‚"])
        Y1(["yâ‚"])
        X1 --> LSTM1
        LSTM1 --> H1
        LSTM1 --> C1
        H1 --> Y1
    end

    subgraph Time_Step_2["t=2"]
        X2(["xâ‚‚"])
        LSTM2["LSTM Cell"]
        H2(["hâ‚‚"])
        C2(["Câ‚‚"])
        Y2(["yâ‚‚"])
        X2 --> LSTM2
        LSTM2 --> H2
        LSTM2 --> C2
        H2 --> Y2
    end

    subgraph Time_Step_3["t=3"]
        X3(["xâ‚ƒ"])
        LSTM3["LSTM Cell"]
        H3(["hâ‚ƒ"])
        C3(["Câ‚ƒ"])
        Y3(["yâ‚ƒ"])
        X3 --> LSTM3
        LSTM3 --> H3
        LSTM3 --> C3
        H3 --> Y3
    end

    H0(["hâ‚€<br/>åˆå§‹éšè—çŠ¶æ€"]) -.-> LSTM1
    C0(["Câ‚€<br/>åˆå§‹ç»†èƒçŠ¶æ€"]) -.-> LSTM1
    H1 -.-> LSTM2
    C1 -.-> LSTM2
    H2 -.-> LSTM3
    C2 -.-> LSTM3

    style LSTM1 fill:#9b59b6,stroke:#333,stroke-width:2px,color:#fff
    style LSTM2 fill:#9b59b6,stroke:#333,stroke-width:2px,color:#fff
    style LSTM3 fill:#9b59b6,stroke:#333,stroke-width:2px,color:#fff
    style H0 fill:#95a5a6,stroke:#333,stroke-width:2px
    style H1 fill:#2ecc71,stroke:#333,stroke-width:2px
    style H2 fill:#2ecc71,stroke:#333,stroke-width:2px
    style H3 fill:#2ecc71,stroke:#333,stroke-width:2px
    style C0 fill:#f39c12,stroke:#333,stroke-width:2px,color:#fff
    style C1 fill:#f39c12,stroke:#333,stroke-width:2px,color:#fff
    style C2 fill:#f39c12,stroke:#333,stroke-width:2px,color:#fff
    style C3 fill:#f39c12,stroke:#333,stroke-width:2px,color:#fff
    style X1 fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style X2 fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style X3 fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
```

**å›¾ä¾‹è¯´æ˜ï¼š**
- ğŸ”´ **çº¢è‰² xâ‚œ**ï¼šå½“å‰æ—¶åˆ»è¾“å…¥
- ğŸŸ£ **ç´«è‰² LSTM Cell**ï¼šå…±äº«å‚æ•°çš„LSTMå•å…ƒ
- ğŸŸ¢ **ç»¿è‰² hâ‚œ**ï¼šéšè—çŠ¶æ€ï¼ˆçŸ­æœŸè®°å¿†ï¼‰
- ğŸŸ¡ **é»„è‰² Câ‚œ**ï¼šç»†èƒçŠ¶æ€ï¼ˆé•¿æœŸè®°å¿†ï¼‰
- âšª **ç°è‰² hâ‚€, Câ‚€**ï¼šåˆå§‹çŠ¶æ€ï¼ˆé€šå¸¸ä¸ºé›¶å‘é‡ï¼‰
- è™šçº¿ç®­å¤´ï¼šçŠ¶æ€çš„è·¨æ—¶é—´æ­¥ä¼ é€’

---

**LSTMå•å…ƒè¯¦ç»†ç»“æ„ï¼š**

```mermaid
flowchart TB
    subgraph LSTM_Cell["LSTM è®¡ç®—å•å…ƒ"]
        direction TB

        %% è¾“å…¥
        Xt(["xâ‚œ<br/>å½“å‰è¾“å…¥"])
        Ht_prev(["hâ‚œâ‚‹â‚<br/>ä¸Šä¸€æ—¶åˆ»éšè—çŠ¶æ€"])
        Ct_prev(["Câ‚œâ‚‹â‚<br/>ä¸Šä¸€æ—¶åˆ»ç»†èƒçŠ¶æ€"])

        %% æƒé‡çŸ©é˜µ
        Wxf["Wâ‚“f<br/>è¾“å…¥-é—å¿˜é—¨æƒé‡"]
        Whf["Wâ‚•f<br/>éšè—-é—å¿˜é—¨æƒé‡"]
        Wxi["Wâ‚“i<br/>è¾“å…¥-è¾“å…¥é—¨æƒé‡"]
        Whi["Wâ‚•i<br/>éšè—-è¾“å…¥é—¨æƒé‡"]
        Wxc["Wâ‚“c<br/>è¾“å…¥-å€™é€‰çŠ¶æ€æƒé‡"]
        Whc["Wâ‚•c<br/>éšè—-å€™é€‰çŠ¶æ€æƒé‡"]
        Wxo["Wâ‚“o<br/>è¾“å…¥-è¾“å‡ºé—¨æƒé‡"]
        Who["Wâ‚•o<br/>éšè—-è¾“å‡ºé—¨æƒé‡"]

        %% é—¨æ§è®¡ç®—
        ForgetGate["Ïƒ<br/>é—å¿˜é—¨ fâ‚œ"]
        InputGate["Ïƒ<br/>è¾“å…¥é—¨ iâ‚œ"]
        Candidate["tanh<br/>å€™é€‰çŠ¶æ€ CÌƒâ‚œ"]
        OutputGate["Ïƒ<br/>è¾“å‡ºé—¨ oâ‚œ"]

        %% ç»†èƒçŠ¶æ€æ›´æ–°
        Mul1["â¨‚<br/>é€å…ƒç´ ä¹˜æ³•"]
        Mul2["â¨‚<br/>é€å…ƒç´ ä¹˜æ³•"]
        Add["â¨<br/>é€å…ƒç´ åŠ æ³•"]

        %% è¾“å‡ºè®¡ç®—
        Tanh["tanh"]
        Mul3["â¨‚<br/>é€å…ƒç´ ä¹˜æ³•"]

        %% è¾“å‡º
        Ct(["Câ‚œ<br/>å½“å‰ç»†èƒçŠ¶æ€"])
        Ht(["hâ‚œ<br/>å½“å‰éšè—çŠ¶æ€"])

        %% è¿æ¥ï¼šè¾“å…¥åˆ°é—¨æ§
        Xt --> Wxf --> ForgetGate
        Ht_prev --> Whf --> ForgetGate
        Xt --> Wxi --> InputGate
        Ht_prev --> Whi --> InputGate
        Xt --> Wxc --> Candidate
        Ht_prev --> Whc --> Candidate
        Xt --> Wxo --> OutputGate
        Ht_prev --> Who --> OutputGate

        %% é—å¿˜é—¨è·¯å¾„
        Ct_prev --> Mul1
        ForgetGate --> Mul1

        %% è¾“å…¥é—¨è·¯å¾„
        InputGate --> Mul2
        Candidate --> Mul2

        %% ç»†èƒçŠ¶æ€æ›´æ–°
        Mul1 --> Add
        Mul2 --> Add
        Add --> Ct

        %% è¾“å‡ºé—¨è·¯å¾„
        Add --> Tanh
        Tanh --> Mul3
        OutputGate --> Mul3
        Mul3 --> Ht
    end

    %% å¾ªç¯è¿æ¥ç¤ºæ„
    Ht -.->|"åé¦ˆåˆ°ä¸‹ä¸€æ—¶åˆ»"| Ht_prev
    Ct -.->|"åé¦ˆåˆ°ä¸‹ä¸€æ—¶åˆ»"| Ct_prev

    %% æ ·å¼
    style Xt fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style Ht_prev fill:#2ecc71,stroke:#333,stroke-width:2px,color:#fff
    style Ct_prev fill:#f39c12,stroke:#333,stroke-width:2px,color:#fff
    style Ht fill:#2ecc71,stroke:#333,stroke-width:2px,color:#fff
    style Ct fill:#f39c12,stroke:#333,stroke-width:2px,color:#fff
    style Wxf fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style Whf fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style Wxi fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style Whi fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style Wxc fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style Whc fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style Wxo fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style Who fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style ForgetGate fill:#9b59b6,stroke:#333,stroke-width:2px,color:#fff
    style InputGate fill:#e67e22,stroke:#333,stroke-width:2px,color:#fff
    style Candidate fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style OutputGate fill:#c0392b,stroke:#333,stroke-width:2px,color:#fff
    style Tanh fill:#34495e,stroke:#333,stroke-width:2px,color:#fff
```

**æ ¸å¿ƒå…¬å¼ï¼š**

```
é—å¿˜é—¨ï¼šfâ‚œ = Ïƒ(Wf Â· [hâ‚œâ‚‹â‚, xâ‚œ] + bf)
è¾“å…¥é—¨ï¼šiâ‚œ = Ïƒ(Wi Â· [hâ‚œâ‚‹â‚, xâ‚œ] + bi)
å€™é€‰çŠ¶æ€ï¼šCÌƒâ‚œ = tanh(Wc Â· [hâ‚œâ‚‹â‚, xâ‚œ] + bc)
ç»†èƒçŠ¶æ€æ›´æ–°ï¼šCâ‚œ = fâ‚œ âŠ™ Câ‚œâ‚‹â‚ + iâ‚œ âŠ™ CÌƒâ‚œ
è¾“å‡ºé—¨ï¼šoâ‚œ = Ïƒ(Wo Â· [hâ‚œâ‚‹â‚, xâ‚œ] + bo)
éšè—çŠ¶æ€ï¼šhâ‚œ = oâ‚œ âŠ™ tanh(Câ‚œ)
```

**å›¾ä¾‹è¯´æ˜ï¼š**
- ğŸŸ£ **ç´«è‰² Ïƒ**ï¼šé—å¿˜é—¨ï¼ˆForget Gateï¼‰â€” å†³å®šä¿ç•™å¤šå°‘æ—§è®°å¿†
- ğŸŸ  **æ©™è‰² Ïƒ**ï¼šè¾“å…¥é—¨ï¼ˆInput Gateï¼‰â€” å†³å®šå­˜å‚¨å¤šå°‘æ–°ä¿¡æ¯
- ğŸŸ¢ **ç»¿è‰² tanh**ï¼šå€™é€‰çŠ¶æ€ â€” ç”Ÿæˆæ–°çš„å€™é€‰è®°å¿†
- ğŸ”´ **çº¢è‰² Ïƒ**ï¼šè¾“å‡ºé—¨ï¼ˆOutput Gateï¼‰â€” å†³å®šè¾“å‡ºå¤šå°‘ä¿¡æ¯
- ğŸ”µ **è“è‰² xâ‚œ**ï¼šå½“å‰æ—¶åˆ»è¾“å…¥
- ğŸŸ¢ **ç»¿è‰² hâ‚œ**ï¼šéšè—çŠ¶æ€ï¼ˆçŸ­æœŸè®°å¿†ï¼‰
- ğŸŸ¡ **é»„è‰² Câ‚œ**ï¼šç»†èƒçŠ¶æ€ï¼ˆé•¿æœŸè®°å¿†ï¼‰
- â­• **â¨‚**ï¼šé€å…ƒç´ ä¹˜æ³•ï¼ˆHadamardç§¯ï¼‰
- â• **â¨**ï¼šé€å…ƒç´ åŠ æ³•

**å…³é”®ç‰¹æ€§ï¼š** LSTMé€šè¿‡ç»†èƒçŠ¶æ€ï¼ˆCâ‚œï¼‰ç›´æ¥ä¼ é€’ä¿¡æ¯ï¼Œé¿å…äº†ä¼ ç»ŸRNNä¸­æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼Œä½¿é‡è¦ä¿¡æ¯å¯ä»¥é•¿è·ç¦»ä¼ é€’è€Œä¸è¡°å‡

---

### 3.2.3 ä¸‰ä¸ªé—¨æ§æœºåˆ¶è¯¦è§£

**1. é—å¿˜é—¨ï¼ˆForget Gateï¼‰â€”â€” å†³å®šä¿ç•™å¤šå°‘æ—§è®°å¿†**

**åŠŸèƒ½ï¼š** æ§åˆ¶å‰ä¸€æ—¶åˆ»çš„ç»†èƒçŠ¶æ€æœ‰å¤šå°‘ä¿¡æ¯è¢«ä¿ç•™åˆ°å½“å‰æ—¶åˆ»

**è®¡ç®—ï¼š**
```
fâ‚œ = Ïƒ(Wf Â· [hâ‚œâ‚‹â‚, xâ‚œ] + bf)
```

**è¾“å‡ºï¼š** fâ‚œ âˆˆ (0, 1)
- `0` = å®Œå…¨é—å¿˜ï¼ˆæ¸…é™¤æ—§è®°å¿†ï¼‰
- `1` = å®Œå…¨ä¿ç•™ï¼ˆä¿æŒæ—§è®°å¿†ä¸å˜ï¼‰

**ç›´è§‚ç†è§£ï¼š**
- `fâ‚œ â‰ˆ 1`ï¼š"è¿™æ¡ä¿¡æ¯å¾ˆé‡è¦ï¼Œç»§ç»­ä¿ç•™"
- `fâ‚œ â‰ˆ 0`ï¼š"è¿™æ¡ä¿¡æ¯ä¸é‡è¦ï¼Œå¯ä»¥å¿˜è®°"

**ç¤ºä¾‹ï¼š**
```
å¥å­ï¼š"æˆ‘å‡ºç”Ÿåœ¨åŒ—äº¬ï¼Œ...ï¼Œæˆ‘ä¼šè¯´ä¸­æ–‡"

åœ¨å¤„ç†"æˆ‘ä¼šè¯´"æ—¶ï¼š
- é—å¿˜é—¨æ£€æµ‹åˆ°ä¸"å‡ºç”Ÿåœ°"ç›¸å…³çš„ä¿¡æ¯
- fâ‚œ â‰ˆ 1ï¼ˆä¿ç•™"åŒ—äº¬"çš„ä¿¡æ¯ï¼‰
- è¿™æ ·"ä¸­æ–‡"å¯ä»¥ä¸"åŒ—äº¬"å»ºç«‹å…³è”
```

---

**2. è¾“å…¥é—¨ï¼ˆInput Gateï¼‰â€”â€” å†³å®šå­˜å‚¨å¤šå°‘æ–°ä¿¡æ¯**

**åŠŸèƒ½ï¼š** æ§åˆ¶å½“å‰è¾“å…¥æœ‰å¤šå°‘ä¿¡æ¯è¢«å†™å…¥ç»†èƒçŠ¶æ€

**è®¡ç®—ï¼š**
```
iâ‚œ = Ïƒ(Wi Â· [hâ‚œâ‚‹â‚, xâ‚œ] + bi)      # è¾“å…¥é—¨ï¼ˆå†³å®šå†™å…¥æ¯”ä¾‹ï¼‰
CÌƒâ‚œ = tanh(Wc Â· [hâ‚œâ‚‹â‚, xâ‚œ] + bc)   # å€™é€‰çŠ¶æ€ï¼ˆæ–°ä¿¡æ¯ï¼‰
```

**è¾“å‡ºï¼š**
- iâ‚œ âˆˆ (0, 1)ï¼šå†™å…¥æ¯”ä¾‹
- CÌƒâ‚œ âˆˆ (-1, 1)ï¼šå€™é€‰è®°å¿†å†…å®¹

**ç›´è§‚ç†è§£ï¼š**
- `iâ‚œ â‰ˆ 1`ï¼š"å½“å‰ä¿¡æ¯å¾ˆé‡è¦ï¼Œå†™å…¥é•¿æœŸè®°å¿†"
- `iâ‚œ â‰ˆ 0`ï¼š"å½“å‰ä¿¡æ¯ä¸é‡è¦ï¼Œä¸å†™å…¥"

**ç¤ºä¾‹ï¼š**
```
å¥å­ï¼š"ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œæˆ‘å¿ƒæƒ…æ„‰å¿«"

åœ¨å¤„ç†"å¿ƒæƒ…æ„‰å¿«"æ—¶ï¼š
- è¾“å…¥é—¨æ£€æµ‹åˆ°æƒ…æ„Ÿä¿¡æ¯
- iâ‚œ â‰ˆ 1ï¼ˆå°†"æ„‰å¿«"å†™å…¥è®°å¿†ï¼‰
- CÌƒâ‚œ ç¼–ç "æ„‰å¿«"çš„è¯­ä¹‰ä¿¡æ¯
```

---

**3. è¾“å‡ºé—¨ï¼ˆOutput Gateï¼‰â€”â€” å†³å®šè¾“å‡ºå¤šå°‘ä¿¡æ¯**

**åŠŸèƒ½ï¼š** æ§åˆ¶ç»†èƒçŠ¶æ€æœ‰å¤šå°‘ä¿¡æ¯è¢«è¾“å‡ºåˆ°éšè—çŠ¶æ€

**è®¡ç®—ï¼š**
```
oâ‚œ = Ïƒ(Wo Â· [hâ‚œâ‚‹â‚, xâ‚œ] + bo)
hâ‚œ = oâ‚œ âŠ™ tanh(Câ‚œ)
```

**è¾“å‡ºï¼š**
- oâ‚œ âˆˆ (0, 1)ï¼šè¾“å‡ºæ¯”ä¾‹
- hâ‚œï¼šå½“å‰æ—¶åˆ»çš„éšè—çŠ¶æ€ï¼ˆçŸ­æœŸè®°å¿†è¾“å‡ºï¼‰

**ç›´è§‚ç†è§£ï¼š**
- `oâ‚œ â‰ˆ 1`ï¼š"å½“å‰éœ€è¦è¾“å‡ºå¤§é‡ä¿¡æ¯"
- `oâ‚œ â‰ˆ 0`ï¼š"å½“å‰åªéœ€è¦è¾“å‡ºå°‘é‡ä¿¡æ¯"

**ç¤ºä¾‹ï¼š**
```
å¥å­ï¼š"è¿™éƒ¨ç”µå½±éå¸¸ç²¾å½©"

åœ¨å¤„ç†"ç²¾å½©"æ—¶ï¼š
- è¾“å‡ºé—¨æ£€æµ‹åˆ°è¿™æ˜¯æƒ…æ„Ÿå…³é”®è¯
- oâ‚œ â‰ˆ 1ï¼ˆå……åˆ†è¾“å‡ºæƒ…æ„Ÿä¿¡æ¯ï¼‰
- hâ‚œ æºå¸¦å¼ºçƒˆçš„æ­£é¢æƒ…æ„Ÿä¿¡å·
```

---

### 3.2.4 ç»†èƒçŠ¶æ€æ›´æ–°æµç¨‹

**ç»†èƒçŠ¶æ€æ›´æ–°ï¼ˆLSTMçš„æ ¸å¿ƒï¼‰ï¼š**

```
Câ‚œ = fâ‚œ âŠ™ Câ‚œâ‚‹â‚ + iâ‚œ âŠ™ CÌƒâ‚œ
      â†‘              â†‘
  ä¿ç•™æ—§è®°å¿†      æ·»åŠ æ–°è®°å¿†
```

**æ›´æ–°æµç¨‹å›¾è§£ï¼š**

```mermaid
flowchart LR
    subgraph UpdateProcess["ç»†èƒçŠ¶æ€æ›´æ–°æµç¨‹"]
        direction TB

        %% è¾“å…¥
        Ct_prev(["Câ‚œâ‚‹â‚<br/>æ—§è®°å¿†"])
        Ft(["fâ‚œ<br/>é—å¿˜é—¨"])
        It(["iâ‚œ<br/>è¾“å…¥é—¨"])
        Ct_tilde(["CÌƒâ‚œ<br/>å€™é€‰è®°å¿†"])

        %% è®¡ç®—
        Mul1["â¨‚<br/>é€å…ƒç´ ä¹˜"]
        Mul2["â¨‚<br/>é€å…ƒç´ ä¹˜"]
        Add["â¨<br/>ç›¸åŠ "]

        %% è¾“å‡º
        Ct(["Câ‚œ<br/>æ›´æ–°åçš„è®°å¿†"])

        %% è¿æ¥
        Ct_prev --> Mul1
        Ft --> Mul1
        It --> Mul2
        Ct_tilde --> Mul2
        Mul1 --> Add
        Mul2 --> Add
        Add --> Ct
    end

    style Ct_prev fill:#f39c12,stroke:#333,stroke-width:2px,color:#fff
    style Ft fill:#9b59b6,stroke:#333,stroke-width:2px,color:#fff
    style It fill:#e67e22,stroke:#333,stroke-width:2px,color:#fff
    style Ct_tilde fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style Ct fill:#f1c40f,stroke:#333,stroke-width:2px,color:#000
    style Mul1 fill:#ecf0f1,stroke:#333,stroke-width:2px
    style Mul2 fill:#ecf0f1,stroke:#333,stroke-width:2px
    style Add fill:#ecf0f1,stroke:#333,stroke-width:2px
```

**å…³é”®ç‰¹æ€§ï¼š**

1. **åŠ æ³•æ›´æ–°**ï¼šç»†èƒçŠ¶æ€é€šè¿‡åŠ æ³•æ›´æ–°ï¼Œè€ŒéRNNçš„ä¹˜æ³•æ›´æ–°
   - RNNï¼šhâ‚œ = tanh(WÂ·hâ‚œâ‚‹â‚ + UÂ·xâ‚œ) â†’ æ¢¯åº¦è¿ä¹˜å¯¼è‡´æ¶ˆå¤±/çˆ†ç‚¸
   - LSTMï¼šCâ‚œ = fâ‚œâŠ™Câ‚œâ‚‹â‚ + iâ‚œâŠ™CÌƒâ‚œ â†’ æ¢¯åº¦ç›´æ¥ä¼ æ’­

2. **çº¿æ€§é€šé“**ï¼šç»†èƒçŠ¶æ€çš„æµåŠ¨å‡ ä¹æ˜¯çº¿æ€§çš„ï¼ˆåªæœ‰é€å…ƒç´ ä¹˜æ³•å’ŒåŠ æ³•ï¼‰
   - è¿™ä½¿å¾—æ¢¯åº¦å¯ä»¥é•¿è·ç¦»ç¨³å®šä¼ æ’­
   - è§£å†³äº†RNNçš„é•¿æœŸä¾èµ–é—®é¢˜

3. **é€‰æ‹©æ€§è®°å¿†**ï¼šé€šè¿‡é—¨æ§æœºåˆ¶é€‰æ‹©æ€§åœ°ä¿ç•™å’Œæ›´æ–°ä¿¡æ¯
   - é—å¿˜é—¨ï¼šå†³å®šå¿˜è®°ä»€ä¹ˆ
   - è¾“å…¥é—¨ï¼šå†³å®šè®°ä½ä»€ä¹ˆ

### 3.2.5 ä¼˜åŠ¿åˆ†æ

**1. è§£å†³é•¿æœŸä¾èµ–é—®é¢˜**

LSTMé€šè¿‡ç»†èƒçŠ¶æ€ï¼ˆCell Stateï¼‰ç›´æ¥ä¼ é€’ä¿¡æ¯ï¼Œé¿å…äº†ä¼ ç»ŸRNNä¸­æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼š

**RNN vs LSTM æ¢¯åº¦ä¼ æ’­å¯¹æ¯”ï¼š**

| ç‰¹æ€§ | RNN | LSTM |
|------|-----|------|
| **çŠ¶æ€æ›´æ–°** | hâ‚œ = tanh(WÂ·hâ‚œâ‚‹â‚ + UÂ·xâ‚œ) | Câ‚œ = fâ‚œ âŠ™ Câ‚œâ‚‹â‚ + iâ‚œ âŠ™ CÌƒâ‚œ |
| **æ¢¯åº¦ä¼ æ’­** | âˆ‚hâ‚œ/âˆ‚hâ‚œâ‚‹â‚ æ¶‰åŠ tanh' å’Œ W çš„è¿ä¹˜ | âˆ‚Câ‚œ/âˆ‚Câ‚œâ‚‹â‚ = fâ‚œï¼ˆé—å¿˜é—¨è¾“å‡ºï¼‰ |
| **é•¿åºåˆ—è¡¨ç°** | æ¢¯åº¦ â†’ 0ï¼ˆæ¶ˆå¤±ï¼‰ | å½“ fâ‚œ â‰ˆ 1 æ—¶ï¼Œæ¢¯åº¦ç¨³å®šä¼ æ’­ |
| **å…³é”®ä¼˜åŠ¿** | - | å¯å­¦ä¹ è®©é—å¿˜é—¨ä¿æŒå¼€å¯ï¼Œä¿¡æ¯é•¿è·ç¦»æµåŠ¨ |

**2. çµæ´»çš„ä¿¡æ¯æ§åˆ¶**

ä¸‰ä¸ªé—¨æ§æœºåˆ¶ä½¿LSTMèƒ½å¤Ÿé€‰æ‹©æ€§åœ°è®°å¿†æˆ–é—å¿˜ï¼š

| åœºæ™¯ | é—å¿˜é—¨ fâ‚œ | è¾“å…¥é—¨ iâ‚œ | è¡Œä¸ºæè¿° |
|------|-----------|-----------|----------|
| ä¿ç•™æ—§ä¿¡æ¯ | â‰ˆ 1 | â‰ˆ 0 | ç»†èƒçŠ¶æ€å‡ ä¹ä¸å˜ï¼Œé•¿æœŸè®°å¿†å¾—ä»¥ä¿ç•™ |
| æ›´æ–°ä¿¡æ¯ | â‰ˆ 0 | â‰ˆ 1 | ä¸¢å¼ƒæ—§ä¿¡æ¯ï¼Œå†™å…¥æ–°ä¿¡æ¯ |
| éƒ¨åˆ†æ›´æ–° | (0,1) | (0,1) | é€‰æ‹©æ€§ä¿ç•™å’Œæ·»åŠ ä¿¡æ¯ |
| å®Œå…¨é‡ç½® | â‰ˆ 0 | â‰ˆ 0 | æ¸…é™¤ç»†èƒçŠ¶æ€ï¼ˆå¥å­è¾¹ç•Œç­‰ï¼‰ |

**3. å®é™…åº”ç”¨ä¼˜åŠ¿**

```
ç¤ºä¾‹ï¼šæœºå™¨ç¿»è¯‘ä¸­çš„é•¿è·ç¦»ä¾èµ–

è¾“å…¥ï¼š"The cat, which was sitting on the mat that was placed 
       near the window overlooking the garden, was hungry."
       
å…³é”®ä¾èµ–ï¼š"cat"(ä¸»è¯­) â†â†’ "was hungry"(è°“è¯­)
è·ç¦»ï¼šç›¸éš”20+ä¸ªè¯

LSTMèƒ½åŠ›ï¼š
- é—å¿˜é—¨ä¿æŒå¼€å¯ï¼Œä¿ç•™"cat"çš„ä¿¡æ¯
- ç»†èƒçŠ¶æ€å°†"cat"çš„ä¿¡æ¯ä¼ é€’åˆ°å¥å­æœ«å°¾
- è¾“å‡ºé—¨åœ¨éœ€è¦æ—¶æå–è¯¥ä¿¡æ¯è¿›è¡Œç¿»è¯‘
```

### 3.2.6 å¤šå±‚ç»“æ„

**åŠ¨æœºï¼š** å•å±‚LSTMåªèƒ½æ•æ‰åŸºç¡€ç‰¹å¾ï¼Œå¤šå±‚LSTMå¯ä»¥å­¦ä¹ å±‚æ¬¡åŒ–çš„è¡¨ç¤ºã€‚

**ç»“æ„è®¾è®¡ï¼š**

```mermaid
flowchart TB
    subgraph Embedding["è¯åµŒå…¥å±‚"]
        direction LR
        E1(["æˆ‘"])
        E2(["éå¸¸"])
        E3(["å–œæ¬¢"])
        E4(["è¿™éƒ¨ç”µå½±"])
    end

    subgraph Layer1["ç¬¬1å±‚ LSTM - è¯çº§ç‰¹å¾"]
        direction LR
        L1_1(["è¯è¡¨ç¤º"])
        L1_2(["è¯è¡¨ç¤º"])
        L1_3(["è¯è¡¨ç¤º"])
        L1_4(["è¯è¡¨ç¤º"])
    end

    subgraph Layer2["ç¬¬2å±‚ LSTM - çŸ­è¯­çº§ç‰¹å¾"]
        direction LR
        L2_1(["æˆ‘"])
        L2_2(["éå¸¸+å–œæ¬¢"])
        L2_3(["è¿™éƒ¨ç”µå½±"])
    end

    subgraph Layer3["ç¬¬3å±‚ LSTM - å¥å­çº§è¯­ä¹‰"]
        direction LR
        L3(["æ­£é¢æƒ…æ„Ÿ"])
    end

    Embedding --> Layer1
    Layer1 --> Layer2
    Layer2 --> Layer3

    style E1 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style E2 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style E3 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style E4 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style L1_1 fill:#2ecc71,stroke:#333,stroke-width:2px
    style L1_2 fill:#2ecc71,stroke:#333,stroke-width:2px
    style L1_3 fill:#2ecc71,stroke:#333,stroke-width:2px
    style L1_4 fill:#2ecc71,stroke:#333,stroke-width:2px
    style L2_1 fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style L2_2 fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style L2_3 fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style L3 fill:#1e8449,stroke:#333,stroke-width:2px,color:#fff
```

**å±‚æ¬¡åŒ–ç‰¹å¾å­¦ä¹ ï¼š**

| å±‚çº§ | ç‰¹å¾ç±»å‹ | å­¦ä¹ å†…å®¹ | é¢œè‰² | ç¤ºä¾‹ |
|------|----------|----------|------|------|
| è¯åµŒå…¥å±‚ | åˆ†å¸ƒå¼è¡¨ç¤º | è¯çš„è¯­ä¹‰å‘é‡ | ğŸ”µ è“è‰² | "æˆ‘"â†’[0.2, -0.5, ...] |
| ç¬¬1å±‚ LSTM | è¯çº§ç‰¹å¾ | å•ä¸ªè¯çš„ä¸Šä¸‹æ–‡è¡¨ç¤º | ğŸŸ¢ æµ…ç»¿ | "å–œæ¬¢"åœ¨å¥ä¸­çš„å«ä¹‰ |
| ç¬¬2å±‚ LSTM | çŸ­è¯­çº§ç‰¹å¾ | è¯ç»„åˆå’Œå±€éƒ¨ç»“æ„ | ğŸŸ¢ ä¸­ç»¿ | "éå¸¸å–œæ¬¢"=ç¨‹åº¦+åŠ¨è¯ |
| ç¬¬3å±‚ LSTM | å¥å­çº§è¯­ä¹‰ | æ•´ä½“ç†è§£å’Œæƒ…æ„Ÿ | ğŸŸ¢ æ·±ç»¿ | "æˆ‘éå¸¸å–œæ¬¢è¿™éƒ¨ç”µå½±"=æ­£é¢ |

**å…³é”®æ´å¯Ÿï¼š**
- ä½å±‚å­¦ä¹ å±€éƒ¨ã€å…·ä½“çš„ç‰¹å¾
- é«˜å±‚å­¦ä¹ æŠ½è±¡ã€å…¨å±€çš„ç‰¹å¾
- é€å±‚æŠ½è±¡ï¼Œå½¢æˆå±‚æ¬¡åŒ–çš„è¯­ä¹‰ç†è§£

**å±‚æ•°é€‰æ‹©å»ºè®®ï¼š**

| å±‚æ•° | é€‚ç”¨åœºæ™¯ | æ³¨æ„äº‹é¡¹ |
|------|----------|----------|
| 1å±‚ | ç®€å•ä»»åŠ¡ã€å°æ•°æ®é›† | å¯èƒ½æ¬ æ‹Ÿåˆ |
| 2å±‚ | å¤§å¤šæ•°NLPä»»åŠ¡ | å¹³è¡¡æ€§èƒ½å’Œæ•ˆç‡ |
| 3-4å±‚ | å¤æ‚ä»»åŠ¡ | éœ€è¦æ›´å¤šæ•°æ®å’Œæ­£åˆ™åŒ– |
| 4å±‚ä»¥ä¸Š | å¾ˆå°‘ä½¿ç”¨ | æ”¶ç›Šé€’å‡ï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆ |

### 3.2.7 åŒå‘ç»“æ„

**åŠ¨æœºï¼š** åœ¨NLPä»»åŠ¡ä¸­ï¼Œç†è§£å½“å‰è¯å¾€å¾€éœ€è¦åŒæ—¶è€ƒè™‘å…¶å‰é¢å’Œåé¢çš„ä¸Šä¸‹æ–‡ã€‚

**ç»“æ„ï¼š**

```mermaid
flowchart TB
    subgraph Input["è¾“å…¥åºåˆ—"]
        direction LR
        X1(["æˆ‘"])
        X2(["å–œæ¬¢"])
        X3(["è‡ªç„¶"])
        X4(["è¯­è¨€"])
    end

    subgraph Forward["å‰å‘LSTM (â†’) - æ•è·ä¸Šæ–‡"]
        direction LR
        F1(["hâƒ—â‚"])
        F2(["hâƒ—â‚‚"])
        F3(["hâƒ—â‚ƒ"])
        F4(["hâƒ—â‚„"])
        F1 --> F2 --> F3 --> F4
    end

    subgraph Backward["åå‘LSTM (â†) - æ•è·ä¸‹æ–‡"]
        direction RL
        B1(["hâƒ–â‚"])
        B2(["hâƒ–â‚‚"])
        B3(["hâƒ–â‚ƒ"])
        B4(["hâƒ–â‚„"])
        B4 --> B3 --> B2 --> B1
    end

    subgraph Output["æœ€ç»ˆè¾“å‡ºï¼ˆæ‹¼æ¥ï¼‰"]
        direction LR
        H1(["hâ‚ = [hâƒ—â‚; hâƒ–â‚]"])
        H2(["hâ‚‚ = [hâƒ—â‚‚; hâƒ–â‚‚]"])
        H3(["hâ‚ƒ = [hâƒ—â‚ƒ; hâƒ–â‚ƒ]"])
        H4(["hâ‚„ = [hâƒ—â‚„; hâƒ–â‚„]"])
    end

    X1 --> F1
    X2 --> F2
    X3 --> F3
    X4 --> F4

    X1 --> B1
    X2 --> B2
    X3 --> B3
    X4 --> B4

    F1 --> H1
    B1 --> H1
    F2 --> H2
    B2 --> H2
    F3 --> H3
    B3 --> H3
    F4 --> H4
    B4 --> H4

    style X1 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style X2 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style X3 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style X4 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style F1 fill:#9b59b6,stroke:#333,stroke-width:2px,color:#fff
    style F2 fill:#9b59b6,stroke:#333,stroke-width:2px,color:#fff
    style F3 fill:#9b59b6,stroke:#333,stroke-width:2px,color:#fff
    style F4 fill:#9b59b6,stroke:#333,stroke-width:2px,color:#fff
    style B1 fill:#e67e22,stroke:#333,stroke-width:2px,color:#fff
    style B2 fill:#e67e22,stroke:#333,stroke-width:2px,color:#fff
    style B3 fill:#e67e22,stroke:#333,stroke-width:2px,color:#fff
    style B4 fill:#e67e22,stroke:#333,stroke-width:2px,color:#fff
    style H1 fill:#2ecc71,stroke:#333,stroke-width:2px
    style H2 fill:#2ecc71,stroke:#333,stroke-width:2px
    style H3 fill:#2ecc71,stroke:#333,stroke-width:2px
    style H4 fill:#2ecc71,stroke:#333,stroke-width:2px
```

**å›¾ä¾‹è¯´æ˜ï¼š**
- ğŸ”µ **è“è‰²è¾“å…¥**ï¼šè¯åµŒå…¥å‘é‡
- ğŸŸ£ **ç´«è‰² hâƒ—**ï¼šå‰å‘LSTMéšè—çŠ¶æ€ï¼ˆä»å·¦åˆ°å³ï¼Œæ•è·ä¸Šæ–‡ä¿¡æ¯ï¼‰
- ğŸŸ  **æ©™è‰² hâƒ–**ï¼šåå‘LSTMéšè—çŠ¶æ€ï¼ˆä»å³åˆ°å·¦ï¼Œæ•è·ä¸‹æ–‡ä¿¡æ¯ï¼‰
- ğŸŸ¢ **ç»¿è‰² h**ï¼šæœ€ç»ˆè¾“å‡ºï¼ˆå‰åå‘æ‹¼æ¥ï¼Œæ•è·å®Œæ•´ä¸Šä¸‹æ–‡ï¼‰

**æ ¸å¿ƒä¼˜åŠ¿ï¼š**
- å‰å‘LSTMï¼šç†è§£"æˆ‘ å–œæ¬¢" â†’ é¢„æµ‹"è‡ªç„¶è¯­è¨€"
- åå‘LSTMï¼šç†è§£"è¯­è¨€å¤„ç†" â†’ é¢„æµ‹"è‡ªç„¶"
- æ‹¼æ¥è¾“å‡ºï¼šåŒæ—¶åˆ©ç”¨å‰åæ–‡ï¼Œå‡†ç¡®ç†è§£æ¯ä¸ªè¯

**åº”ç”¨åœºæ™¯ï¼š**

| ä»»åŠ¡ | ä¸ºä»€ä¹ˆéœ€è¦åŒå‘ | ç¤ºä¾‹ |
|------|----------------|------|
| å‘½åå®ä½“è¯†åˆ« | ç¡®å®šå®ä½“è¾¹ç•Œéœ€è¦å‰åæ–‡ | "åŒ—äº¬å¤§å­¦"éœ€è¦çœ‹åˆ°"åŒ—äº¬"å’Œ"å¤§å­¦"æ‰èƒ½ç¡®å®šæ˜¯ORG |
| æƒ…æ„Ÿåˆ†æ | å¦å®šè¯å¯èƒ½åœ¨åé¢ | "è¿™éƒ¨ç”µå½±ä¸å·®"éœ€è¦çœ‹åˆ°"ä¸"å’Œ"å·®"æ‰èƒ½ç¡®å®šæƒ…æ„Ÿ |
| è¯æ€§æ ‡æ³¨ | è¯æ€§ä¾èµ–ä¸Šä¸‹æ–‡ | "record"å¯ä»¥æ˜¯åè¯æˆ–åŠ¨è¯ï¼Œéœ€è¦çœ‹å‰åè¯ç¡®å®š |

### 3.2.8 å¤šå±‚+åŒå‘ç»“æ„

**åŠ¨æœºï¼š** ç»“åˆå¤šå±‚ç»“æ„å’ŒåŒå‘ç»“æ„çš„ä¼˜åŠ¿ï¼ŒåŒæ—¶æ•è·å±‚æ¬¡åŒ–ç‰¹å¾å’Œå®Œæ•´ä¸Šä¸‹æ–‡ã€‚

**ç»“æ„è®¾è®¡ï¼š**

```mermaid
flowchart TB
    subgraph Input["è¾“å…¥å±‚ï¼ˆè¯åµŒå…¥ï¼‰"]
        direction LR
        X1(["xâ‚"])
        X2(["xâ‚‚"])
        X3(["xâ‚ƒ"])
        X4(["xâ‚„"])
        X1 --> X2 --> X3 --> X4
    end

    subgraph Layer1["ç¬¬1å±‚ åŒå‘LSTM"]
        direction TB
        subgraph L1_F["å‰å‘ (â†’)"]
            direction LR
            H11F(["hâ‚â½Â¹â¾"]) --> H12F(["hâ‚‚â½Â¹â¾"]) --> H13F(["hâ‚ƒâ½Â¹â¾"]) --> H14F(["hâ‚„â½Â¹â¾"])
        end
        subgraph L1_B["åå‘ (â†)"]
            direction RL
            H14B(["hâ‚„â½Â¹â¾"]) --> H13B(["hâ‚ƒâ½Â¹â¾"]) --> H12B(["hâ‚‚â½Â¹â¾"]) --> H11B(["hâ‚â½Â¹â¾"])
        end
    end

    subgraph Layer2["ç¬¬2å±‚ åŒå‘LSTM"]
        direction TB
        subgraph L2_F["å‰å‘ (â†’)"]
            direction LR
            H21F(["hâ‚â½Â²â¾"]) --> H22F(["hâ‚‚â½Â²â¾"]) --> H23F(["hâ‚ƒâ½Â²â¾"]) --> H24F(["hâ‚„â½Â²â¾"])
        end
        subgraph L2_B["åå‘ (â†)"]
            direction RL
            H24B(["hâ‚„â½Â²â¾"]) --> H23B(["hâ‚ƒâ½Â²â¾"]) --> H22B(["hâ‚‚â½Â²â¾"]) --> H21B(["hâ‚â½Â²â¾"])
        end
    end

    subgraph Layer3["ç¬¬3å±‚ åŒå‘LSTM"]
        direction TB
        subgraph L3_F["å‰å‘ (â†’)"]
            direction LR
            H31F(["hâ‚â½Â³â¾"]) --> H32F(["hâ‚‚â½Â³â¾"]) --> H33F(["hâ‚ƒâ½Â³â¾"]) --> H34F(["hâ‚„â½Â³â¾"])
        end
        subgraph L3_B["åå‘ (â†)"]
            direction RL
            H34B(["hâ‚„â½Â³â¾"]) --> H33B(["hâ‚ƒâ½Â³â¾"]) --> H32B(["hâ‚‚â½Â³â¾"]) --> H31B(["hâ‚â½Â³â¾"])
        end
    end

    Input --> Layer1
    Layer1 --> Layer2
    Layer2 --> Layer3

    style X1 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style X2 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style X3 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style X4 fill:#3498db,stroke:#333,stroke-width:2px,color:#fff
    style H11F fill:#2ecc71,stroke:#333,stroke-width:2px
    style H12F fill:#2ecc71,stroke:#333,stroke-width:2px
    style H13F fill:#2ecc71,stroke:#333,stroke-width:2px
    style H14F fill:#2ecc71,stroke:#333,stroke-width:2px
    style H11B fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style H12B fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style H13B fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style H14B fill:#e74c3c,stroke:#333,stroke-width:2px,color:#fff
    style H21F fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style H22F fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style H23F fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style H24F fill:#27ae60,stroke:#333,stroke-width:2px,color:#fff
    style H21B fill:#c0392b,stroke:#333,stroke-width:2px,color:#fff
    style H22B fill:#c0392b,stroke:#333,stroke-width:2px,color:#fff
    style H23B fill:#c0392b,stroke:#333,stroke-width:2px,color:#fff
    style H24B fill:#c0392b,stroke:#333,stroke-width:2px,color:#fff
    style H31F fill:#1e8449,stroke:#333,stroke-width:2px,color:#fff
    style H32F fill:#1e8449,stroke:#333,stroke-width:2px,color:#fff
    style H33F fill:#1e8449,stroke:#333,stroke-width:2px,color:#fff
    style H34F fill:#1e8449,stroke:#333,stroke-width:2px,color:#fff
    style H31B fill:#922b21,stroke:#333,stroke-width:2px,color:#fff
    style H32B fill:#922b21,stroke:#333,stroke-width:2px,color:#fff
    style H33B fill:#922b21,stroke:#333,stroke-width:2px,color:#fff
    style H34B fill:#922b21,stroke:#333,stroke-width:2px,color:#fff
```

**å›¾ä¾‹è¯´æ˜ï¼š**
- ğŸ”µ **è“è‰² x**ï¼šè¾“å…¥è¯åµŒå…¥
- ğŸŸ¢ **ç»¿è‰² hâƒ—**ï¼šå‰å‘éšè—çŠ¶æ€ï¼ˆæ¯å±‚é¢œè‰²æ·±æµ…é€’å¢ï¼‰
- ğŸ”´ **çº¢è‰² hâƒ–**ï¼šåå‘éšè—çŠ¶æ€ï¼ˆæ¯å±‚é¢œè‰²æ·±æµ…é€’å¢ï¼‰
- æ¯å±‚è¾“å‡º = [å‰å‘éšè—çŠ¶æ€ ; åå‘éšè—çŠ¶æ€] çš„æ‹¼æ¥

**æ¶æ„ä¼˜åŠ¿ï¼š**
1. **å‚ç›´æ–¹å‘**ï¼šå¤šå±‚å †å ï¼Œé€å±‚æŠ½è±¡ï¼ˆè¯çº§â†’çŸ­è¯­çº§â†’å¥å­çº§ï¼‰
2. **æ°´å¹³æ–¹å‘**ï¼šåŒå‘å¤„ç†ï¼Œæ•è·å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆä¸Šæ–‡+ä¸‹æ–‡ï¼‰

### 3.2.9 APIä½¿ç”¨

**PyTorch LSTM APIï¼š**

```python
import torch
import torch.nn as nn

# åŸºæœ¬LSTM
lstm = nn.LSTM(
    input_size=input_size,    # è¾“å…¥ç‰¹å¾ç»´åº¦
    hidden_size=hidden_size,  # éšè—å±‚ç»´åº¦
    num_layers=num_layers,    # å±‚æ•°
    bias=True,               # æ˜¯å¦ä½¿ç”¨åç½®
    batch_first=False,        # è¾“å…¥æ˜¯å¦ä¸º(batch, seq, feature)
    dropout=0,               # å±‚é—´dropoutæ¦‚ç‡ï¼ˆnum_layers>1æ—¶æœ‰æ•ˆï¼‰
    bidirectional=False,      # æ˜¯å¦åŒå‘
    proj_size=0              # æŠ•å½±å±‚å¤§å°ï¼ˆå¯é€‰ï¼‰
)

# è¾“å…¥å½¢çŠ¶ï¼š(seq_len, batch_size, input_size)
# å¦‚æœbatch_first=Trueï¼Œåˆ™ä¸º(batch_size, seq_len, input_size)
input = torch.randn(10, 32, 100)  # 10ä¸ªæ—¶é—´æ­¥ï¼Œ32ä¸ªbatchï¼Œ100ç»´è¾“å…¥

# åˆå§‹éšè—çŠ¶æ€ï¼š(num_layers * num_directions, batch_size, hidden_size)
h0 = torch.randn(num_layers, 32, hidden_size)
# åˆå§‹ç»†èƒçŠ¶æ€ï¼š(num_layers * num_directions, batch_size, hidden_size)
c0 = torch.randn(num_layers, 32, hidden_size)

# å‰å‘ä¼ æ’­
output, (hn, cn) = lstm(input, (h0, c0))
# outputå½¢çŠ¶ï¼š(seq_len, batch_size, num_directions * hidden_size)
# hnå½¢çŠ¶ï¼š(num_layers * num_directions, batch_size, hidden_size)
# cnå½¢çŠ¶ï¼š(num_layers * num_directions, batch_size, hidden_size)
```

**å¸¸ç”¨å‚æ•°è¯´æ˜ï¼š**

| å‚æ•° | è¯´æ˜ | æ¨èå€¼ |
|------|------|--------|
| input_size | è¾“å…¥ç‰¹å¾ç»´åº¦ | è¯å‘é‡ç»´åº¦ï¼ˆå¦‚100, 300ï¼‰ |
| hidden_size | éšè—å±‚ç»´åº¦ | 64-512ï¼Œæ ¹æ®ä»»åŠ¡å¤æ‚åº¦ |
| num_layers | å±‚æ•° | 1-3å±‚ |
| batch_first | æ˜¯å¦ä»¥batchä¸ºç¬¬ä¸€ç»´åº¦ | Trueï¼ˆç¬¦åˆç›´è§‰ï¼‰ |
| bidirectional | æ˜¯å¦åŒå‘ | ä»»åŠ¡éœ€è¦å®Œæ•´ä¸Šä¸‹æ–‡æ—¶ä½¿ç”¨ |
| dropout | å±‚é—´dropout | 0.1-0.5ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰ |

**è¾“å…¥è¾“å‡ºå†…å®¹è¯¦è§£ï¼š**

| ç±»å‹ | å‚æ•° | è¯´æ˜ | å½¢çŠ¶ |
|------|------|------|------|
| **è¾“å…¥** | **input** | è¾“å…¥åºåˆ— | `(seq_len, batch_size, input_size)`ï¼Œå¦‚æœ `batch_first=True`ï¼Œåˆ™ä¸º `(batch_size, seq_len, input_size)` |
| | **h_0** | å¯é€‰ï¼Œåˆå§‹éšè—çŠ¶æ€ | `(num_layers Ã— num_directions, batch_size, hidden_size)` |
| | **c_0** | å¯é€‰ï¼Œåˆå§‹ç»†èƒçŠ¶æ€ | `(num_layers Ã— num_directions, batch_size, hidden_size)` |
| **è¾“å‡º** | **output** | LSTMå±‚çš„è¾“å‡ºï¼ŒåŒ…å«æœ€åä¸€å±‚æ¯ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ | `(seq_len, batch_size, num_directions Ã— hidden_size)`ï¼Œå¦‚æœ `batch_first=True`ï¼Œåˆ™ä¸º `(batch_size, seq_len, num_directions Ã— hidden_size)` |
| | **h_n** | æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€ï¼ŒåŒ…å«æ¯ä¸€å±‚çš„æ¯ä¸ªæ–¹å‘ | `(num_layers Ã— num_directions, batch_size, hidden_size)` |
| | **c_n** | æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„ç»†èƒçŠ¶æ€ï¼ŒåŒ…å«æ¯ä¸€å±‚çš„æ¯ä¸ªæ–¹å‘ | `(num_layers Ã— num_directions, batch_size, hidden_size)` |

### 3.2.10 æ¡ˆä¾‹å®æ“ï¼ˆAIæ™ºè¯„V2.0ï¼‰

#### é¡¹ç›®æ¦‚è¿°

æœ¬æ¡ˆä¾‹å®ç°ä¸€ä¸ªåŸºäºLSTMçš„ä¸­æ–‡è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿï¼ˆAIæ™ºè¯„V2.0ï¼‰ï¼Œèƒ½å¤Ÿè‡ªåŠ¨åˆ¤æ–­ç”¨æˆ·è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘ï¼ˆæ­£å‘/è´Ÿå‘ï¼‰ã€‚é¡¹ç›®å®Œæ•´ä»£ç ä½äº `review_analyze_lstm` ç›®å½•ä¸‹ã€‚

#### æ ¸å¿ƒæ€è·¯

**ä»»åŠ¡å®šä¹‰ï¼š** ç»™å®šä¸€æ¡è¯„è®ºæ–‡æœ¬ï¼Œé¢„æµ‹å…¶æƒ…æ„Ÿå€¾å‘ï¼ˆ0=è´Ÿå‘ï¼Œ1=æ­£å‘ï¼‰

```
è¾“å…¥æ–‡æœ¬ï¼š"è¿™æ¬¾æ‰‹æœºçœŸçš„å¤ªå¥½ç”¨äº†ï¼Œå¼ºçƒˆæ¨èï¼"
æ¨¡å‹è¾“å‡ºï¼šæ­£å‘æƒ…æ„Ÿï¼ˆæ¦‚ç‡ï¼š0.92ï¼‰

å¤„ç†æµç¨‹ï¼š
1. åˆ†è¯ï¼š["è¿™æ¬¾", "æ‰‹æœº", "çœŸçš„", "å¤ªå¥½ç”¨", "äº†", "ï¼Œ", "å¼ºçƒˆ", "æ¨è", "ï¼"]
2. ç¼–ç ï¼š[45, 892, 123, 567, 8, 2, 234, 789, 3]
3. LSTMç¼–ç  â†’ æå–ç‰¹å¾
4. åˆ†ç±»ï¼šæ­£å‘ï¼ˆæ¦‚ç‡>0.5ï¼‰
```

#### é¡¹ç›®ç»“æ„

```
review_analyze_lstm/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py      # é…ç½®æ–‡ä»¶ï¼ˆè·¯å¾„ã€è¶…å‚æ•°ï¼‰
â”‚   â”œâ”€â”€ process.py     # æ•°æ®é¢„å¤„ç†ï¼ˆæ¸…æ´—ã€åˆ†è¯ã€ç¼–ç ã€åˆ’åˆ†ï¼‰
â”‚   â”œâ”€â”€ dataset.py     # Datasetç±»å’ŒDataLoader
â”‚   â”œâ”€â”€ model.py       # LSTMæ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ train.py       # è®­ç»ƒæµç¨‹
â”‚   â”œâ”€â”€ evaluate.py    # æ¨¡å‹è¯„ä¼°
â”‚   â”œâ”€â”€ predict.py     # é¢„æµ‹æ¥å£
â”‚   â””â”€â”€ tokenizer.py   # åˆ†è¯å™¨å®ç°
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/           # åŸå§‹è¯„è®ºæ•°æ®
â”‚   â””â”€â”€ processed/     # å¤„ç†åçš„è®­ç»ƒ/æµ‹è¯•é›†
â”œâ”€â”€ models/            # ä¿å­˜çš„è¯è¡¨å’Œæ¨¡å‹æƒé‡
â””â”€â”€ logs/              # TensorBoardæ—¥å¿—
```

#### è¯¦ç»†å®ç°

> **ã€ä¸RNNæ¡ˆä¾‹çš„å¯¹æ¯”è¯´æ˜ã€‘**
> 
> æœ¬æ¡ˆä¾‹ä¸RNNæ¡ˆä¾‹ï¼ˆæ™ºèƒ½è¾“å…¥æ³•ï¼‰ç›¸æ¯”ï¼Œæœ‰ä»¥ä¸‹æ ¸å¿ƒå·®å¼‚ï¼š
> 
> | å¯¹æ¯”ç»´åº¦ | RNNæ¡ˆä¾‹ | LSTMæ¡ˆä¾‹ï¼ˆæœ¬æ¡ˆä¾‹ï¼‰ |
> |----------|---------|-------------------|
> | **ä»»åŠ¡ç±»å‹** | å¤šåˆ†ç±»ï¼ˆé¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼‰ | äºŒåˆ†ç±»ï¼ˆæƒ…æ„Ÿåˆ†æï¼‰ |
> | **è¾“å‡ºç»´åº¦** | vocab_size | 1 |
> | **æ¨¡å‹ç»“æ„** | `nn.RNN` | `nn.LSTM`ï¼ˆå¢åŠ ç»†èƒçŠ¶æ€ï¼‰ |
> | **æŸå¤±å‡½æ•°** | `CrossEntropyLoss` | `BCEWithLogitsLoss` |
> | **åºåˆ—å¤„ç†** | å›ºå®šé•¿åº¦ï¼Œç›´æ¥å–æœ€åä¸€ç»´ | å˜é•¿åºåˆ—ï¼Œé€šè¿‡padding_idxæ‰¾æœ‰æ•ˆé•¿åº¦ |
> | **å‰å‘ä¼ æ’­è¿”å›å€¼** | `output, hidden` | `output, (hidden, cell)` |
> 
> ä»¥ä¸‹ä»£ç ä¸­ï¼Œ**ã€ä¸RNNå·®å¼‚ã€‘** æ ‡è®°è¡¨ç¤ºä¸RNNæ¡ˆä¾‹ä¸åŒçš„éƒ¨åˆ†ã€‚

**1. é…ç½®æ–‡ä»¶ï¼ˆconfig.pyï¼‰**

> æ–‡ä»¶è·¯å¾„ï¼š`review_analyze_lstm/src/config.py`

```python
"""
é…ç½®æ–‡ä»¶æ¨¡å—

åŠŸèƒ½æè¿°:
    æœ¬æ¨¡å—å®šä¹‰äº†è¾“å…¥æ³•LSTMæ¨¡å‹çš„å…¨å±€é…ç½®å‚æ•°ï¼ŒåŒ…æ‹¬æ•°æ®è·¯å¾„ã€æ¨¡å‹è¶…å‚æ•°ç­‰ã€‚
    æ‰€æœ‰è·¯å¾„å‡åŸºäºé¡¹ç›®æ ¹ç›®å½•è¿›è¡Œå®šä¹‰ï¼Œç¡®ä¿è·¨å¹³å°å…¼å®¹æ€§ã€‚

ä½œè€…: Red_Moon
åˆ›å»ºæ—¥æœŸ: 2026-02
"""

from pathlib import Path

# =============================================================================
# è·¯å¾„é…ç½®
# =============================================================================
ROOT_DIR = Path(__file__).parent.parent

RAW_DATA_DIR = ROOT_DIR / "data" / "raw"
PROCESSED_DATA_DIR = ROOT_DIR / "data" / "processed"
LOGS_DIR = ROOT_DIR / "logs"
MODELS_DIR = ROOT_DIR / "models"


# =============================================================================
# æ¨¡å‹è¶…å‚æ•°é…ç½®
# =============================================================================
# ã€ä¸RNNå·®å¼‚ã€‘åºåˆ—é•¿åº¦æ›´é•¿ï¼ˆRNNé€šå¸¸è¾ƒçŸ­ï¼Œå¦‚5-10ï¼›LSTMå¯å¤„ç†æ›´é•¿åºåˆ—ï¼‰
SEQ_LEN = 128
BATCH_SIZE = 64
EMBEDDING_DIM = 128
HIDDEN_SIZE = 256
LEARNING_RATE = 1e-3
EPOCHS = 50
```

**2. æ•°æ®é¢„å¤„ç†ï¼ˆprocess.pyï¼‰**

> æ–‡ä»¶è·¯å¾„ï¼š`review_analyze_lstm/src/process.py`

```python
"""
æ•°æ®é¢„å¤„ç†æ¨¡å—

åŠŸèƒ½æè¿°:
    æœ¬æ¨¡å—å®ç°äº†æƒ…æ„Ÿåˆ†æä»»åŠ¡çš„æ•°æ®é¢„å¤„ç†æµç¨‹ã€‚
    ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼šåŸå§‹æ•°æ®åŠ è½½ã€è®­ç»ƒ/æµ‹è¯•é›†åˆ’åˆ†ã€è¯è¡¨æ„å»ºã€
    æ–‡æœ¬ç¼–ç å’ŒJSONLæ ¼å¼æ•°æ®ä¿å­˜ã€‚

ä½œè€…: Red_Moon
åˆ›å»ºæ—¥æœŸ: 2026-02
"""

from sklearn.model_selection import train_test_split
from tokenizer import JiebaTokenizer
import config
import pandas as pd


def process():
    """
    æ‰§è¡Œå®Œæ•´çš„æ•°æ®é¢„å¤„ç†æµç¨‹

    å¤„ç†æµç¨‹:
        1. è¯»å–åŸå§‹CSVæ•°æ®ï¼ˆonline_shopping_10_cats.csvï¼‰
        2. é€‰æ‹©labelå’Œreviewåˆ—ï¼Œåˆ é™¤ç¼ºå¤±å€¼
        3. é‡‡æ ·10%æ•°æ®ç”¨äºå¿«é€Ÿå®éªŒï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
        4. æŒ‰æ ‡ç­¾åˆ†å±‚åˆ’åˆ†è®­ç»ƒé›†(80%)å’Œæµ‹è¯•é›†(20%)
        5. åŸºäºè®­ç»ƒé›†æ„å»ºè¯è¡¨å¹¶ä¿å­˜
        6. ä½¿ç”¨åˆ†è¯å™¨å°†æ–‡æœ¬ç¼–ç ä¸ºè¯ç´¢å¼•åºåˆ—
        7. ä¿å­˜å¤„ç†åçš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸ºJSONLæ ¼å¼
    """
    print("å¼€å§‹å¤„ç†æ•°æ®")
    # ã€ä¸RNNå·®å¼‚ã€‘ä½¿ç”¨CSVæ ¼å¼è€ŒéJSONLï¼Œä¸”åŒ…å«æ ‡ç­¾åˆ—ï¼ˆæƒ…æ„Ÿåˆ†æéœ€è¦ï¼‰
    df = pd.read_csv(config.RAW_DATA_DIR / "online_shopping_10_cats.csv", 
                     usecols=["label", "review"], 
                     encoding="utf-8").dropna().sample(frac=0.1)

    train_df, test_df = train_test_split(df, test_size=0.2, stratify=df["label"])

    JiebaTokenizer.build_vocab(train_df['review'].tolist(), config.MODELS_DIR / 'vocab.txt')

    tokenizer = JiebaTokenizer.from_vocab(config.MODELS_DIR / 'vocab.txt')

    train_df['review'] = train_df['review'].apply(lambda x: tokenizer.encode(x, config.SEQ_LEN))
    train_df.to_json(config.PROCESSED_DATA_DIR / 'train.jsonl', orient='records', lines=True)

    test_df['review'] = test_df['review'].apply(lambda x: tokenizer.encode(x, config.SEQ_LEN))
    test_df.to_json(config.PROCESSED_DATA_DIR / 'test.jsonl', orient='records', lines=True)
    print("æ•°æ®å¤„ç†ç»“æŸ")
```

**3. æ¨¡å‹å®šä¹‰ï¼ˆmodel.pyï¼‰**

> æ–‡ä»¶è·¯å¾„ï¼š`review_analyze_lstm/src/model.py`

```python
"""
æ¨¡å‹å®šä¹‰æ¨¡å—

åŠŸèƒ½æè¿°:
    æœ¬æ¨¡å—å®šä¹‰äº†åŸºäºLSTMçš„æƒ…æ„Ÿåˆ†ææ¨¡å‹ReviewAnalyzeModelã€‚
    æ¨¡å‹ç»“æ„ï¼šEmbeddingå±‚ -> LSTMå±‚ -> Linearå±‚
    æ”¯æŒå˜é•¿åºåˆ—å¤„ç†ï¼Œé€šè¿‡æå–æœ€åä¸€ä¸ªæœ‰æ•ˆæ—¶é—´æ­¥çš„éšè—çŠ¶æ€è¿›è¡Œåˆ†ç±»ã€‚

ä½œè€…: Red_Moon
åˆ›å»ºæ—¥æœŸ: 2026-02
"""

import torch.nn as nn
import config
import torch


class ReviewAnalyzeModel(nn.Module):
    """
    ã€ä¸RNNå·®å¼‚ã€‘åŸºäºLSTMçš„è¯„è®ºæƒ…æ„Ÿåˆ†ææ¨¡å‹

    æ¶æ„è¯´æ˜:
        1. Embeddingå±‚: å°†è¯ç´¢å¼•æ˜ å°„ä¸ºç¨ å¯†å‘é‡è¡¨ç¤º
        2. LSTMå±‚: å»ºæ¨¡åºåˆ—çš„æ—¶åºä¾èµ–å…³ç³»ï¼Œæ•è·ä¸Šä¸‹æ–‡ä¿¡æ¯
           ã€ä¸RNNå·®å¼‚ã€‘LSTMå¢åŠ ç»†èƒçŠ¶æ€ï¼Œå¯è§£å†³é•¿æœŸä¾èµ–é—®é¢˜
        3. Linearå±‚: å°†LSTMæœ€ç»ˆéšè—çŠ¶æ€æ˜ å°„åˆ°è¾“å‡ºç©ºé—´
           ã€ä¸RNNå·®å¼‚ã€‘è¾“å‡ºç»´åº¦ä¸º1ï¼ˆäºŒåˆ†ç±»ï¼‰ï¼Œè€Œévocab_size
    """

    def __init__(self, vocab_size, padding_index):
        """
        åˆå§‹åŒ–æ¨¡å‹

        å‚æ•°:
            vocab_size (int): è¯è¡¨å¤§å°ï¼Œå†³å®šEmbeddingå±‚çš„è¾“å…¥ç»´åº¦
            padding_index (int): ã€ä¸RNNå·®å¼‚ã€‘å¡«å……æ ‡è®°<pad>çš„ç´¢å¼•ï¼Œç”¨äºå¤„ç†å˜é•¿åºåˆ—
        """
        super().__init__()
        # ã€ä¸RNNå·®å¼‚ã€‘å¢åŠ padding_idxå‚æ•°ï¼Œæ”¯æŒå˜é•¿åºåˆ—å¤„ç†
        self.embedding = nn.Embedding(vocab_size, config.EMBEDDING_DIM, padding_idx=padding_index)
        # ã€ä¸RNNå·®å¼‚ã€‘ä½¿ç”¨nn.LSTMæ›¿ä»£nn.RNNï¼Œå¢åŠ ç»†èƒçŠ¶æ€
        self.lstm = nn.LSTM(input_size=config.EMBEDDING_DIM, hidden_size=config.HIDDEN_SIZE, batch_first=True)
        # ã€ä¸RNNå·®å¼‚ã€‘è¾“å‡ºç»´åº¦ä¸º1ï¼ˆäºŒåˆ†ç±»ï¼‰ï¼Œè€Œévocab_sizeï¼ˆå¤šåˆ†ç±»ï¼‰
        self.linear = nn.Linear(config.HIDDEN_SIZE, 1)

    def forward(self, x: torch.Tensor):
        """
        å‰å‘ä¼ æ’­

        å‚æ•°:
            x (torch.Tensor): è¾“å…¥è¯ç´¢å¼•åºåˆ—ï¼Œå½¢çŠ¶ä¸º[batch_size, seq_len]

        è¿”å›:
            torch.Tensor: æƒ…æ„Ÿé¢„æµ‹logitsï¼Œå½¢çŠ¶ä¸º[batch_size]
        """
        # x.shape : [batch_size, seq_len]
        embed = self.embedding(x)
        # embed.shape : [batch_size, seq_len, embedding_dim]
        # ã€ä¸RNNå·®å¼‚ã€‘LSTMè¿”å›(output, (hidden, cell))ï¼ŒRNNè¿”å›(output, hidden)
        lstm_out, (_, _) = self.lstm(embed)
        # lstm_out.shape : [batch_size, seq_len, hidden_size]
        # ã€ä¸RNNå·®å¼‚ã€‘å¤„ç†å˜é•¿åºåˆ—ï¼šé€šè¿‡padding_idxæ‰¾åˆ°æ¯ä¸ªåºåˆ—çš„å®é™…é•¿åº¦
        batch_indexes = torch.arange(0, lstm_out.shape[0])
        lengths = (x != self.embedding.padding_idx).sum(dim=1)
        last_hidden = lstm_out[batch_indexes, lengths - 1]
        # ã€RNNå·®å¼‚å¯¹æ¯”ã€‘RNNæ¡ˆä¾‹ç›´æ¥å–output[:, -1, :]ï¼Œå‡è®¾å›ºå®šé•¿åº¦
        # last_hidden.shape : [batch_size, hidden_size]
        out = self.linear(last_hidden).squeeze(-1)
        # out.shape : [batch_size]
        return out
```

**4. è®­ç»ƒæµç¨‹ï¼ˆtrain.pyï¼‰**

> æ–‡ä»¶è·¯å¾„ï¼š`review_analyze_lstm/src/train.py`

```python
"""
æ¨¡å‹è®­ç»ƒæ¨¡å—

åŠŸèƒ½æè¿°:
    æœ¬æ¨¡å—å®ç°äº†åŸºäºLSTMçš„æƒ…æ„Ÿåˆ†ææ¨¡å‹çš„å®Œæ•´è®­ç»ƒæµç¨‹ã€‚

ä½œè€…: Red_Moon
åˆ›å»ºæ—¥æœŸ: 2026-02
"""

import time
from tqdm import tqdm
import torch
import torch.nn as nn
from dataset import get_dataloader
from model import ReviewAnalyzeModel
from tokenizer import JiebaTokenizer
import config
from torch.utils.tensorboard import SummaryWriter


def train_one_epoch(model, dataloader, loss_fn, optimizer, device):
    """
    è®­ç»ƒä¸€ä¸ªepoch

    è®­ç»ƒæµç¨‹:
        1. è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
        2. éå†æ•°æ®åŠ è½½å™¨
        3. å‰å‘ä¼ æ’­ã€è®¡ç®—æŸå¤±ã€åå‘ä¼ æ’­ã€æ›´æ–°å‚æ•°
    """
    model.train()
    total_loss = 0
    for inputs, targets in tqdm(dataloader):
        inputs, targets = inputs.to(device), targets.to(device)
        outputs = model(inputs)
        loss = loss_fn(outputs, targets)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(dataloader)


def train():
    """
    å®Œæ•´çš„æ¨¡å‹è®­ç»ƒæµç¨‹
    """
    # 1. è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # 2. æ•°æ®
    dataloader = get_dataloader()
    # 3. åˆ†è¯å™¨
    tokenizer = JiebaTokenizer.from_vocab(config.MODELS_DIR / "vocab.txt")
    # 4. æ¨¡å‹
    # ã€ä¸RNNå·®å¼‚ã€‘ä¼ å…¥padding_indexå‚æ•°ï¼Œæ”¯æŒå˜é•¿åºåˆ—
    model = ReviewAnalyzeModel(vocab_size=tokenizer.vocab_size, 
                               padding_index=tokenizer.pad_token_index).to(device)
    # 5. ã€ä¸RNNå·®å¼‚ã€‘äºŒåˆ†ç±»æŸå¤±å‡½æ•°ï¼šBCEWithLogitsLoss
    #    RNNæ¡ˆä¾‹ä½¿ç”¨ï¼šCrossEntropyLossï¼ˆå¤šåˆ†ç±»ï¼‰
    loss_fn = torch.nn.BCEWithLogitsLoss()
    # 6. ä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE)
    # 7. TensorBoard Writer
    writer = SummaryWriter(log_dir=config.LOGS_DIR / time.strftime('%Y-%m-%d_%H-%M-%S'))

    best_loss = float('inf')
    for epoch in range(1, config.EPOCHS + 1):
        print(f'======= Epoch {epoch} =======')
        loss = train_one_epoch(model, dataloader, loss_fn, optimizer, device)
        print(f'loss:{loss:.4f}')
        writer.add_scalar('loss', loss, epoch)
        if loss < best_loss:
            best_loss = loss
            torch.save(model.state_dict(), config.MODELS_DIR / 'best.pt')
            print("ä¿å­˜æ¨¡å‹")
    writer.close()
```

**5. é¢„æµ‹æ¥å£ï¼ˆpredict.pyï¼‰**

> æ–‡ä»¶è·¯å¾„ï¼š`review_analyze_lstm/src/predict.py`

```python
"""
æ¨¡å‹é¢„æµ‹æ¨¡å—

åŠŸèƒ½æè¿°:
    æœ¬æ¨¡å—å®ç°äº†åŸºäºLSTMçš„æƒ…æ„Ÿåˆ†ææ¨¡å‹çš„é¢„æµ‹åŠŸèƒ½ã€‚
    æ”¯æŒæ‰¹é‡é¢„æµ‹å’Œå•æ¡æ–‡æœ¬é¢„æµ‹ï¼Œæä¾›äº¤äº’å¼å‘½ä»¤è¡Œç•Œé¢ã€‚

ä½œè€…: Red_Moon
åˆ›å»ºæ—¥æœŸ: 2026-02
"""

import torch
import config
from model import ReviewAnalyzeModel
from tokenizer import JiebaTokenizer


def predict_batch(model, inputs):
    """
    æ‰¹é‡é¢„æµ‹

    åŠŸèƒ½æè¿°:
        å¯¹è¾“å…¥æ‰¹æ¬¡è¿›è¡Œæƒ…æ„Ÿé¢„æµ‹ï¼Œè¿”å›æ¯ä¸ªæ ·æœ¬å±äºæ­£å‘æƒ…æ„Ÿçš„æ¦‚ç‡ã€‚
    """
    model.eval()
    with torch.no_grad():
        output = model(inputs)
    # ã€ä¸RNNå·®å¼‚ã€‘äºŒåˆ†ç±»ä½¿ç”¨sigmoidè·å–æ¦‚ç‡ï¼Œå¤šåˆ†ç±»ä½¿ç”¨softmax
    batch_result = torch.sigmoid(output)
    return batch_result.tolist()


def predict(text, model, tokenizer, device):
    """
    å•æ¡æ–‡æœ¬é¢„æµ‹

    åŠŸèƒ½æè¿°:
        å¯¹å•æ¡æ–‡æœ¬è¿›è¡Œæƒ…æ„Ÿåˆ†æé¢„æµ‹ï¼Œè¿”å›è¯¥æ–‡æœ¬å±äºæ­£å‘æƒ…æ„Ÿçš„æ¦‚ç‡ã€‚
    """
    indexes = tokenizer.encode(text, seq_len=config.SEQ_LEN)
    input_tensor = torch.tensor([indexes], dtype=torch.long).to(device)
    batch_result = predict_batch(model, input_tensor)
    return batch_result[0]


def run_predict():
    """
    è¿è¡Œäº¤äº’å¼é¢„æµ‹ç•Œé¢
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    tokenizer = JiebaTokenizer.from_vocab(config.MODELS_DIR / 'vocab.txt')
    print("è¯è¡¨åŠ è½½æˆåŠŸ")

    # ã€ä¸RNNå·®å¼‚ã€‘ä¼ å…¥padding_indexå‚æ•°
    model = ReviewAnalyzeModel(vocab_size=tokenizer.vocab_size, 
                               padding_index=tokenizer.pad_token_index).to(device)
    model.load_state_dict(torch.load(config.MODELS_DIR / 'best.pt'))
    print("æ¨¡å‹åŠ è½½æˆåŠŸ")

    print("\n" + "=" * 40)
    print("æ¬¢è¿ä½¿ç”¨æƒ…æ„Ÿåˆ†ææ¨¡å‹(è¾“å…¥qæˆ–è€…quité€€å‡º)")
    print("=" * 40)

    while True:
        user_input = input("> ")
        if user_input in ['q', 'quit']:
            print("æ¬¢è¿ä¸‹æ¬¡å†æ¥")
            break
        if user_input.strip() == '':
            print("è¯·è¾“å…¥å†…å®¹")
            continue

        result = predict(user_input, model, tokenizer, device)
        print(f'é¢„æµ‹ç»“æœ: {result}')
        # ã€ä¸RNNå·®å¼‚ã€‘äºŒåˆ†ç±»ç»“æœè§£é‡Šï¼ˆ>0.5ä¸ºæ­£ï¼Œ<0.5ä¸ºè´Ÿï¼‰
        if result > 0.5:
            print(f"æ­£å‘è¯„è®º,ç½®ä¿¡åº¦:{result}")
        else:
            print(f"è´Ÿå‘è¯„è®º,ç½®ä¿¡åº¦:{1-result}")
        print("-" * 40)
```

#### è¿è¡Œç¤ºä¾‹

```bash
# 1. æ•°æ®é¢„å¤„ç†
python src/process.py

# 2. è®­ç»ƒæ¨¡å‹
python src/train.py

# 3. è¯„ä¼°æ¨¡å‹
python src/evaluate.py

# 4. äº¤äº’å¼é¢„æµ‹
python src/predict.py
```

é¢„æµ‹æ•ˆæœï¼š
```
ä½¿ç”¨è®¾å¤‡: cuda
è¯è¡¨åŠ è½½æˆåŠŸ
æ¨¡å‹åŠ è½½æˆåŠŸ

========================================
æ¬¢è¿ä½¿ç”¨æƒ…æ„Ÿåˆ†ææ¨¡å‹(è¾“å…¥qæˆ–è€…quité€€å‡º)
========================================
> è¿™æ¬¾æ‰‹æœºè´¨é‡å¤ªå·®äº†ï¼Œå®Œå…¨ä¸å€¼è¿™ä¸ªä»·
é¢„æµ‹ç»“æœ: 0.12
è´Ÿå‘è¯„è®º,ç½®ä¿¡åº¦:0.88
----------------------------------------
> éå¸¸æ»¡æ„ï¼Œç‰©æµå¾ˆå¿«ï¼Œå•†å“è´¨é‡å¾ˆå¥½
é¢„æµ‹ç»“æœ: 0.91
æ­£å‘è¯„è®º,ç½®ä¿¡åº¦:0.91
```

### 3.2.11 å­˜åœ¨é—®é¢˜

**1. å‚æ•°é‡è¾ƒå¤§**

LSTMç›¸æ¯”RNNæœ‰æ˜¾è‘—çš„å‚æ•°é‡å¢åŠ ï¼š

| æ¨¡å‹ | å‚æ•°é‡å…¬å¼ | ç¤ºä¾‹ï¼ˆinput=100, hidden=128ï¼‰ |
|------|-----------|------------------------------|
| RNN | 1 Ã— (input + hidden) Ã— hidden | 29,184 |
| LSTM | 4 Ã— (input + hidden) Ã— hidden | 116,736 |

LSTMçš„å‚æ•°é‡æ˜¯RNNçš„4å€ï¼Œè¿™å¯¼è‡´ï¼š
- éœ€è¦æ›´å¤šçš„è®­ç»ƒæ•°æ®
- è®­ç»ƒæ—¶é—´æ›´é•¿
- æ›´å®¹æ˜“è¿‡æ‹Ÿåˆ

**2. è®¡ç®—å¤æ‚åº¦è¾ƒé«˜**

æ¯ä¸ªæ—¶é—´æ­¥éœ€è¦è¿›è¡Œï¼š
- 4æ¬¡çŸ©é˜µä¹˜æ³•ï¼ˆé—å¿˜é—¨ã€è¾“å…¥é—¨ã€å€™é€‰çŠ¶æ€ã€è¾“å‡ºé—¨ï¼‰
- å¤šæ¬¡é€å…ƒç´ è¿ç®—

è¿™ä½¿å¾—LSTMçš„æ¨ç†é€Ÿåº¦æ¯”RNNæ…¢ï¼Œä¸é€‚åˆå®æ—¶æ€§è¦æ±‚æé«˜çš„åœºæ™¯ã€‚

**3. ç¼“è§£æ–¹æ³•**

| æ–¹æ³• | åŸç† | æ•ˆæœ |
|------|------|------|
| ä½¿ç”¨GRU | å‡å°‘é—¨æ§æ•°é‡ï¼ˆ3â†’2ï¼‰ | å‚æ•°é‡å‡å°‘25%ï¼Œé€Ÿåº¦æå‡ |
| æ¨¡å‹å‰ªæ | ç§»é™¤ä¸é‡è¦çš„æƒé‡ | å‡å°‘å‚æ•°é‡ï¼Œä¿æŒæ€§èƒ½ |
| é‡åŒ– | ä½¿ç”¨ä½ç²¾åº¦è¡¨ç¤º | å‡å°‘å†…å­˜å ç”¨ï¼ŒåŠ é€Ÿæ¨ç† |
| çŸ¥è¯†è’¸é¦ | ç”¨å¤§æ¨¡å‹æ•™å°æ¨¡å‹ | å°æ¨¡å‹è¾¾åˆ°æ¥è¿‘å¤§æ¨¡å‹çš„æ•ˆæœ |

---

## ç›¸å…³æ–‡æ¡£

- [RNNï¼ˆå¾ªç¯ç¥ç»ç½‘ç»œï¼‰](./03_RNN.md) - LSTMçš„åŸºç¡€ç‰ˆæœ¬ï¼Œç†è§£RNNæœ‰åŠ©äºæŒæ¡LSTM
- [GRUï¼ˆé—¨æ§å¾ªç¯å•å…ƒï¼‰](./03_GRU.md) - LSTMçš„ç®€åŒ–ç‰ˆæœ¬ï¼Œå‚æ•°æ›´å°‘ï¼Œè®­ç»ƒæ›´å¿«

---

## å‚è€ƒèµ„æº

- PyTorchå®˜æ–¹æ–‡æ¡£ï¼šhttps://pytorch.org/docs/stable/nn.html#lstm
- ç»å…¸è®ºæ–‡ï¼š
  - LSTM: "Long Short-Term Memory" (1997) - Hochreiter & Schmidhuber
